[{"body":"简要概述 gRPC 的优势 核心应用场景\n高性能分布式系统\n低延迟 \u0026 高吞吐：基于 HTTP/2 协议的多路复用和二进制编码，显著减少网络开销，适合微服务间高频通信。 强扩展性：支持每秒数万级 RPC 调用，满足高并发需求（如电商大促、游戏服务器）。 移动端与云端通信\n弱网优化：二进制传输比 REST/JSON 更省带宽，提升移动端响应速度。 跨平台兼容：自动生成 iOS/Android 客户端 SDK 代码，确保多端行为一致。 定制化协议设计\n精准高效：通过 Protocol Buffers 定义严格的接口和数据结构，避免手动解析错误。 语言无关：一套 .proto 文件生成 Java/Python/Go 等多语言代码，解决异构系统协作问题。 可扩展的中间件支持\n分层架构：原生支持或通过拦截器（Interceptor）扩展以下功能： 认证：集成 JWT、OAuth2 等。 负载均衡：内置客户端负载均衡（如 gRPC-LB）。 可观测性：无缝对接 Prometheus、OpenTelemetry 实现监控和日志。 对比 REST 的优势\n维度 gRPC REST/JSON 传输效率 二进制编码，体积小、解析快 文本传输，冗余度高 协议灵活性 支持流式通信（单/双向流） 通常限于请求-响应模式 开发体验 自动生成强类型代码，减少手写错误 需手动处理序列化/反序列化 何时不推荐使用？\n浏览器直接调用：需依赖 grpc-web、grpc-gateway 转译（部分功能受限）。 简单读操作为主：如公开 API，REST 的易调试性可能更优。 如何建立连接 在 grpc 中，客户端与服务端可以是异构语言编写，比如服务端使用 go，客户端可分别是 nodejs、python 等语言编写。\n服务端均使用 Protocol Buffers 语言定义，但客户端依赖服务端提供 stub（存根，编译的时候根据客户端目标语言生成，类似 sdk），才可以发起连接并建立请求解析服务端响应。\n以下是服务端与多个客户端之间示例流程图：\nsequenceDiagram gRPC Stub (nodejs client)-\u003e\u003egRPC Server (go server): Proto Request gRPC Server (go server)-\u003e\u003egRPC Stub (nodejs client): Proto Response gRPC Stub (python client)-\u003e\u003egRPC Server (go server): Proto Request gRPC Server (go server)-\u003e\u003egRPC Stub (python client): Proto Response Protocol Buffers 在 grpc 系统中是使用 protocol buffer 进行序列化的（对比 http 协议下常用的 json 数据结构）。\nprotocol buffers 存在两种版本，proto2 与 proto3，一般现在使用均建议使用版本3。\nRPC 服务类型 单次 RPC （Unary RPC） 客户端发送单个请求并接收单个响应，也就是“一问一答”。\n当客户端调用存根方法时：\nRPC调用通知\n服务端立即收到调用通知，包含：\n✓ 客户端元数据（metadata）\n✓ 调用的方法名\n✓ 可选的超时截止时间（deadline） 服务端响应流程\n初始元数据阶段：\n服务端可选择立即发送初始元数据（必须在响应体之前发送），或等待客户端请求消息。具体顺序由业务逻辑决定。 请求处理阶段：\n服务端获取客户端请求消息后，执行业务逻辑并生成响应。 服务端响应返回\n响应包含：\n✓ 响应体（业务数据）\n✓ 状态详情（状态码 + 可选状态信息）\n✓ 可选的尾部元数据（trailing metadata） 若状态为OK，客户端将成功接收响应，完成本次调用。 示例流程图\nsequenceDiagram gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response 服务端流式 RPC （Server streaming RPC） 与单次 RPC（Unary RPC）类似，不同之处在于：服务端在响应客户端请求时，会返回一个消息流。\n核心流程\n客户端发送单个请求（与单次 RPC 相同）。 服务端返回消息流： 服务端可以持续发送多个消息（而非单个响应）。 消息流传输完成后，服务端会附带状态信息（状态码 + 可选的状态消息）和尾部元数据（trailing metadata），以标志本次 RPC 处理完成。 客户端接收完整消息流： 客户端会持续接收服务端返回的消息，直到获取所有数据后，本次 RPC 调用才正式完成。 对比单次 RPC（Unary RPC）\n特性 单次 RPC 服务端流式 RPC 请求方式 单次请求 单次请求 响应方式 单次响应 消息流（多次响应） 适用场景 简单查询 大数据分批传输、实时推送 典型应用\n数据分块传输（如大文件下载） 实时数据推送（如股票行情、日志流） 长任务分阶段返回（如机器学习模型推理） 示例流程图\nsequenceDiagram gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request (1) gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response (1) gRPC Server (go server)-\u003e\u003egRPC Stub (go client): ...... gRPC Server (go server)-\u003e\u003egRPC Stub (go client): ...... gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response (n) 客户端流式 RPC（Client streaming RPC） 与单次 RPC（Unary RPC）类似，但区别在于：客户端会向服务端发送一个消息流（而非单个请求），而服务端最终返回单个响应（附带状态信息和可选的尾部元数据）。\n核心流程\n客户端发送消息流： 客户端通过持久化连接持续发送多个请求消息（如分批上传数据）。 服务端处理并返回响应： 服务端可以边接收边处理，但通常会在接收完所有客户端消息后，再返回最终响应（包含状态码、状态消息和尾部元数据）。 调用完成： 客户端收到服务端的最终响应后，本次 RPC 调用结束。 对比单次 RPC（Unary RPC）\n特性 单次 RPC 客户端流式 RPC 请求方式 单次请求 消息流（多次请求） 响应方式 单次响应 单次响应 适用场景 简单操作 数据分批上传、长请求 典型应用\n大数据上传（如日志批量采集） 聚合计算（如客户端发送多个数据点，服务端汇总后返回结果） 长请求处理（如流式语音识别，客户端持续发送音频片段） 示例流程图\nsequenceDiagram gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request (1) gRPC Stub (go client)-\u003e\u003egRPC Server (go server): ...... gRPC Stub (go client)-\u003e\u003egRPC Server (go server): ...... gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request (n) gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response (1) 双向流式 RPC（Bidirectional streaming RPC） 由客户端发起调用，服务端接收客户端元数据、方法名和截止时间后，可选择立即返回初始元数据，或等待客户端开始发送消息流。\n核心特点\n独立双工通信\n客户端和服务端可同时发送消息流，两者完全独立，没有固定顺序约束。 支持灵活交互模式，例如： 顺序处理：服务端收齐所有客户端消息后再响应。 实时交互：类似“乒乓模式”（请求-响应-再请求-再响应）。 动态控制流\n服务端可在连接期间任意时机发送初始元数据或消息。 客户端和服务端可自主决定读写时序，无需严格同步。 对比其他 RPC 模式\n特性 单次 RPC 服务端流式 客户端流式 双向流式 请求流 单次 单次 消息流 消息流 响应流 单次 消息流 单次 消息流 交互自由度 低 中 中 高 典型应用场景\n实时对话系统（如聊天应用，双方随时发送消息） 双向数据同步（如游戏状态同步） 复杂协作流程（如客户端与服务端分阶段交换计算中间结果） 示例流程图\nsequenceDiagram gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request (1) gRPC Stub (go client)-\u003e\u003egRPC Server (go server): ...... gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response (1) gRPC Stub (go client)-\u003e\u003egRPC Server (go server): ...... gRPC Stub (go client)-\u003e\u003egRPC Server (go server): Proto Request (n) gRPC Server (go server)-\u003e\u003egRPC Stub (go client): ...... gRPC Server (go server)-\u003e\u003egRPC Stub (go client): Proto Response (n) 超时与截止时间 连接时长限制 在建立连接时，允许客户端为每次 RPC 调用设置截止时间（Deadline）或超时时长（Timeout）。若请求未在指定时间内完成，RPC 将自动终止并返回 DEADLINE_EXCEEDED 错误，当然服务端也可主动检查当前请求是否已超时或剩余可用时间还剩多少。\n超时核心机制 客户端设置\n截止时间（Deadline）：指定一个绝对时间点（如 2025-05-16 15:26:38）。 超时时长（Timeout）：指定相对时间长度（如 5秒）。 不同编程语言的 API 可能仅支持以上其中一种形式，如下两种语言的实现差异：\n# python 示例（使用相对 timeout） response = stub.SayHello(hello_pb2.HelloRequest(name='grpc-kit'), timeout=5) // go 示例（使用绝对 deadline） ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(5*time.Second)) defer cancel() response, err := client.SayHello(ctx, \u0026pb.HelloRequest{Name: \"grpc-kit\"}) 服务端处理\n服务端可通过 API 查询： 当前 RPC 是否已超时； 剩余可用的处理时间（用于动态调整任务优先级）。 网络延迟不计入超时，RPC 的截止时间涵盖： 请求传输； 服务端处理； 响应返回的全流程。 在 “客户端x1-\u003e服务端y1/客户端x2-\u003e服务端y2“ 之间的级联传递： 若服务端作为其他 RPC 服务的客户端，需手动传递或重新设置截止时间，避免上游超时未触发下游终止； 通过 metadata 将 deadline 传递给下游服务，保持调用链超时一致性。 底层实现中，gRPC 最终都会将 timeout 转换为 deadline 进行计算 在使用 go 语言实现的服务端，可以通过 context.Context 检查超时状态：\nfunc (m *Microservice) SayHello(ctx context.Context, req *pb.HelloRequest) (*pb.HelloResponse, error) { if ctx.Err() == context.DeadlineExceeded { // 清理已进行的操作 return nil, status.Error(codes.DeadlineExceeded, \"client deadline exceeded\") } // 获取剩余时间 deadline, ok := ctx.Deadline() remaining := time.Until(deadline) // 根据剩余时间调整处理逻辑 } 典型应用场景 一般在以下场景下使用：\n快速失败（Fail Fast）：避免长时间阻塞的调用拖慢系统。 资源优化：服务端通过剩余时间决定是否执行耗时操作。 建议通过实际压测确定最佳超时值，通常建议：\n服务间调用：500ms-5s； 用户直接请求：1-30s； 后台作业：可适当延长但必须显式设置上限。 最后提醒 deadline 不是精确的时间保证，实际触发时间可能会有数百毫秒的误差，不能依赖其实现精确的定时功能。\n请求的终止机制 四类终止情况 在 RPC 调用可能因以下情况终止：\n超时终止（Deadline Exceeded）\n客户端设置的截止时间（Deadline）或超时（Timeout）到期，RPC 自动终止，并返回 DEADLINE_EXCEEDED 错误。 适用场景：防止长时间阻塞，确保系统响应能力。 显式取消（Cancellation）\n客户端或服务端可主动取消正在进行的 RPC，终止未完成的请求。 适用场景：用户取消操作、服务端资源不足等。 错误终止（Error Termination）\n若 RPC 执行过程中发生错误（如网络中断、服务不可用），会自动终止并返回对应的错误状态码（如 UNAVAILABLE）。 正常完成（Normal Completion）\nRPC 成功执行并返回预期结果后，连接正常关闭。 关键区别：\n终止类型 触发方式 典型错误码 超时终止 客户端设置的时间到期 DEADLINE_EXCEEDED 显式取消 手动调用取消方法 CANCELLED 错误终止 网络/服务端异常 UNAVAILABLE、ABORTED 正常完成 请求成功处理完毕 OK（无错误） 显式取消 在请求建立完成后，客户端或服务端均可随时取消正在进行的 RPC，取消操作会立即终止连接，后续所有相关处理均被中断。\n存在以下核心特性：\n即时生效 取消请求一旦触发，RPC 会立刻停止，不再执行任何后续逻辑（包括网络传输和服务端处理）。 客户端和服务端会收到 CANCELLED 状态码（错误码 1）。 双向能力 客户端取消：例如用户主动取消请求或前端页面关闭。 服务端取消：例如服务端资源不足或检测到无效请求时主动终止。 资源释放 取消后，双方应释放已占用的连接、线程等资源，避免内存泄漏。 典型应用场景：\n客户端侧：用户中断长时间等待的请求。 服务端侧： 检测到恶意请求或参数错误时主动取消。 负载过高时终止低优先级 RPC。 与超时终止的区别：\n行为 取消（Cancellation） 超时（Deadline） 触发方 客户端或服务端手动调用 客户端设置的计时器自动触发 错误码 CANCELLED (1) DEADLINE_EXCEEDED (4) 控制粒度 精确到单次 RPC 调用 依赖全局 Deadline 设置 最佳实践 客户端：\n提供显式的取消按钮或超时逻辑。 捕获 CANCELLED 错误并记录日志（非必要不重试）。 错误恢复策略：客户端应处理 DEADLINE_EXCEEDED 和 CANCELLED，考虑重试或降级逻辑。 服务端：\n监听取消信号，及时回滚事务或清理临时数据。 避免在取消后继续写入响应流。 合理设置 Deadline：避免过长（浪费资源）或过短（频繁超时）。 资源清理：监听取消信号，及时释放占用的资源。 Metadata 设计解析 通信信封：类似 HTTP Headers，但专为 gRPC 优化设计 双向流动： graph LR Client--\u003e|Request Metadata|Server Server--\u003e|Response Metadata|Client 生命周期：仅存在于单个 RPC 调用上下文 传输载体：底层通过 HTTP/2 HEADERS 帧传输 键命名规范：\n关键规则 合法示例 非法示例 禁止 grpc- 前缀 app-version grpc-token 允许字符：a-z,0-9,-,_,. x-b3-traceid user@info 二进制键必须-bin结尾 auth-token-bin image_data 大小写不敏感 CLIENT-ID与client-id等价 - 性能关键点：\n大小限制：建议单个元数据不超过4KB（受HTTP/2规范限制） 压缩策略：对于重复键值建议使用HPACK压缩 缓存机制：高频使用的元数据应复用Metadata对象 二进制优化：二进制数据建议使用Base64编码（某些语言实现需要） 跨语言实现 语言特性注意事项\n语言 关键特性 Python 使用元组列表表示，二进制值需转换为bytes Go 通过context传递，区分header/trailer Java 需要ASCII_STRING_MARSHALLER处理非ASCII字符 C++ 使用MetadataMap容器类，支持直接内存访问 Node.js 通过Metadata类管理，二进制值需Buffer类型 客户端发送元数据 # Python示例 from grpc import Metadata metadata = Metadata( ('client-id', 'python-app'), ('auth-token-bin', b'\\x89PNG\\r\\n\\x1a\\n') ) response = stub.UnaryCall(request, metadata=metadata) // Go示例 md := metadata.Pairs( \"client-id\", \"go-service\", \"auth-token-bin\", string([]byte{0x89, 0x50, 0x4E, 0x47}), ) ctx := metadata.NewOutgoingContext(context.Background(), md) resp, err := client.SomeMethod(ctx, req) 服务端读取元数据 // Java服务端 public void someMethod(HelloRequest request, StreamObserver\u003cHelloResponse\u003e responseObserver) { Metadata headers = MetadataUtils.headersFrom(request); String clientId = headers.get(Metadata.Key.of(\"client-id\", Metadata.ASCII_STRING_MARSHALLER)); // 添加响应元数据 Metadata trailingHeaders = new Metadata(); trailingHeaders.put(Metadata.Key.of(\"server-load\", Metadata.ASCII_STRING_MARSHALLER), \"0.75\"); responseObserver.onNext(response); responseObserver.onCompleted(trailingHeaders); } 流式RPC元数据交互\n// 客户端流式发送元数据 func (s *server) ClientStreaming(stream pb.Service_ClientStreamingServer) error { // 读取初始元数据 md, _ := metadata.FromIncomingContext(stream.Context()) // 流处理中发送响应元数据 header := metadata.Pairs(\"stream-status\", \"processing\") stream.SendHeader(header) // 流结束时发送尾部元数据 trailer := metadata.Pairs(\"processed-count\", \"1234\") stream.SetTrailer(trailer) return nil } 调试与监控 可通过 Wireshark 抓包分析，选择条目右击 “Decode As…\"，对 “Current” 更改为 “HTTP2” 类型。\nHEADERS 帧示例：\n:path: /default.api.oneops.netdev.v1.OneopsNetdev/CreateDeviceNetconfStream :authority: 127.0.0.1:10081 :method: POST :scheme: http content-type: application/grpc te: trailers grpc-accept-encoding: identity, deflate, gzip grpc-timeout: 4990m user-agent: grpc-python-asyncio/1.71.0 grpc-c/46.0.0 (osx; chttp2) authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 应用场景 场景类型 元数据示例 说明 认证鉴权 authorization: Bearer xxxx 携带JWT/OAuth2 token 链路追踪 x-b3-traceid: 463ac35c9f6413ad 分布式追踪上下文 流量控制 canary-flag: true 灰度发布标识 内容协商 content-encoding: snappy 数据压缩格式 调试信息 debug-mode: verbose 开启服务端详细日志 二进制传输 image-data-bin: \u003cbinary\u003e 传输小尺寸二进制载荷 最佳实践清单\n命名规范：\n使用kebab-case命名风格（如api-version） 业务自定义键添加项目前缀（如myapp-feature-flag） 生命周期管理：\nRequest Metadata → 服务端处理 → Response Metadata ↓ Trailing Metadata 使用上安全实践：\n# 不安全示例（明文传输敏感信息） metadata = Metadata(('password', 'qwerty123')) # 安全实践 metadata = Metadata( ('authorization', f'Bearer {jwt_token}'), ('x-encrypted-data-bin', encrypt(payload)) ) 错误处理模式：\nfunc validateMetadata(md metadata.MD) error { if md.Get(\"authorization\") == nil { return status.Error(codes.Unauthenticated, \"missing auth\") } // 验证二进制数据 if token := md.Get(\"signature-bin\"); len(token) != 64 { return status.Error(codes.InvalidArgument, \"invalid signature\") } return nil } 关键结论：\nMetadata 机制是 gRPC 实现可观察性和上下文传递的核心设计，其灵活性与性能需要开发者通过以下平衡：\n信息密度 vs 传输效率 开发便利性 vs 类型安全 业务扩展性 vs 协议稳定性 正确使用 Metadata 可以使分布式系统获得以下能力：\n[上下文传递] → [认证鉴权] → [链路追踪] → [流量控制] ↓ ↓ ↓ ↓ 事务关联 安全边界 性能分析 系统弹性 Channels 设计理念 Channel 是 gRPC 客户端的战略资源，其正确使用直接影响：\n系统可靠性 ←→ 资源利用率 ←→ 运维复杂度 开发者需要重点把握：\n生命周期管理：创建、重用、关闭的规范 状态感知：实时监控连接健康度 配置调优：根据业务场景调整参数 跨语言一致性：理解不同实现的细微差异 通过合理设计 Channel 使用策略，可实现：\n[高性能连接池] → [智能负载均衡] → [弹性容错机制] ↓ ↓ ↓ 高吞吐量 流量最优分配 自动故障恢复 面向客户端应用，它有以下特点：\n客户端入口点：所有 RPC 调用的起点 资源管理器：统一管理连接池、负载均衡策略、压缩设置等 虚拟连接抽象：一个 Channel 代表到目标主机的逻辑连接 graph TD Client[客户端应用] --\u003e Channel Channel --\u003e LB[负载均衡策略] Channel --\u003e CP[连接池] Channel --\u003e Compress[压缩配置] Channel --\u003e TLS[安全配置] 生命周期 状态机模型\nCREATED → CONNECTING → READY → TRANSIENT_FAILURE → (重试)→ READY ↓ ↓ IDLE SHUTDOWN 状态转换触发条件\n状态 触发场景 典型持续时间 CONNECTING 首次建立连接 网络RTT时间 READY 成功建立至少一个连接 长期保持 TRANSIENT_FAILURE 连接中断但可恢复（如临时网络故障） 指数退避重试期间 IDLE 无活动RPC超过keepalive时间 直到新请求触发重连 SHUTDOWN 显式关闭Channel 永久状态 跨语言差异对比 语言 Channel创建 状态查询API 关闭行为 Go grpc.Dial(\"host:port\", opts...) conn.GetState() 必须显式Close() Python grpc.insecure_channel(...) channel._channel.check_connectivity_state() 自动GC回收 Java ManagedChannelBuilder getState(true) shutdown() + awaitTermination() C++ CreateChannel() GetState() 引用计数控制 Node.js new Client('host:port', creds) 无直接API 自动关闭 性能相关 // Go示例 conn, err := grpc.Dial( \"service.example.com:443\", grpc.WithDefaultServiceConfig(`{ \"loadBalancingConfig\": [{\"round_robin\":{}}], \"methodConfig\": [{ \"name\": [{\"service\": \"echo.Echo\"}], \"retryPolicy\": { \"maxAttempts\": 3, \"initialBackoff\": \"0.1s\", \"maxBackoff\": \"1s\", \"backoffMultiplier\": 2, \"retryableStatusCodes\": [\"UNAVAILABLE\"] } }] }`), grpc.WithTransportCredentials(credentials.NewTLS(\u0026tls.Config{}))) 安全相关 # Python安全配置示例 channel = grpc.secure_channel( 'api.example.com:50051', grpc.composite_channel_credentials( grpc.ssl_channel_credentials(root_certificates), grpc.access_token_call_credentials('Bearer ' + token) ), options=(('grpc.primary_user_agent', 'myapp/1.0'),) 最佳实践指南 Channel 复用策略 +----------------+ +-----------------+ | 客户端进程 | | 服务端集群 | | | | | | [Channel A] |---LB----\u003e| Instance1:50051 | | (单例) | | Instance2:50051 | | | | Instance3:50051 | +----------------+ +-----------------+ 每个服务端点维护一个Channel单例 避免为每个RPC创建新Channel（高开销） 多线程环境下保证线程安全 优雅关闭模式 // Java正确关闭示例 ManagedChannel channel = ManagedChannelBuilder.forTarget(\"localhost:50051\") .usePlaintext() .build(); // 使用channel... channel.shutdown(); // 启动关闭流程 try { if (!channel.awaitTermination(5, TimeUnit.SECONDS)) { channel.shutdownNow(); // 强制关闭 } } catch (InterruptedException e) { channel.shutdownNow(); } 状态监控集成 // Go状态监控示例 go func() { for { state := conn.GetState() metrics.RecordChannelState(state.String()) if !conn.WaitForStateChange(ctx, state) { break } } }() 性能优化要点 参数 推荐值 影响维度 keepalive_time 60s 连接保活频率 keepalive_timeout 20s 保活响应等待 max_concurrent_streams 100 HTTP/2流并发数 initial_window_size 1MB 流控窗口初始值 max_connection_age 30min 连接最大生命周期 避免每次新建 Channel # 错误示例（Python） def make_request(request): with grpc.insecure_channel('localhost:50051') as channel: # 频繁创建销毁 stub = service_pb2_grpc.MyServiceStub(channel) return stub.Call(request) 忽略 TRANSIENT_FAILURE 状态 // 错误处理方式 conn, _ := grpc.Dial(...) for { if resp, err := client.Call(ctx, req); err != nil { time.Sleep(1 * time.Second) // 未检测连接状态 continue } break } 客户端负载均衡配置 [Channel] | +-----------+-----------+ | | DNS-based ServiceConfig-based (简单轮询) (高级策略) | | grpclb xDS配置 | | +-------+-------+ +-------+-------+ | | | | 后端实例1 后端实例2 CDN节点1 CDN节点2 ","categories":"","description":"","excerpt":"简要概述 gRPC 的优势 核心应用场景\n高性能分布式系统\n低延迟 \u0026 高吞吐：基于 HTTP/2 协议的多路复用和二进制编码，显著减少网络 …","ref":"/docs/concepts/grpc/grpc/","tags":"","title":"RPC 简介"},{"body":"简要概述 通过 gitlab ci 服务，进行流水线构建，流水线语法参考。\nPipeline 模版 文件路径 .gitlab/workflows/grpc-kit.yml 因 gitlab-ci.yml、github action 中的 yaml 文件使用后缀 .yml ，所以其他以 yaml 编写的流水线均按照此规范。\n模版内容 # 默认全局配置 default: # TODO；根据具体情况选择运行的 runner 标签 tags: - grpc-kit # TODO; 依赖文件注意使用缓存，避免每次下载 #cache: # paths: # - /go/pkg/mod/ # 框架使用的构建镜像 image: ccr.ccs.tencentyun.com/grpc-kit/cli:0.3.1 # 默认全局变量 variables: CGO_ENABLED: \"0\" GIT_SSL_NO_VERIFY: \"true\" GO111MODULE: \"on\" GOPROXY: \"https://goproxy.cn\" GOSUMDB: \"sum.golang.google.cn\" GOPRIVATE: \"https://git.lmq.io\" # 流水线各阶段 stages: - pre - test - build - deploy - production # 代码风格、格式检测 go-lint: stage: pre script: - make lint # 依赖的相关依赖的组件 check-dep: stage: pre script: - which go - which protoc - which protoc-gen-go - which protoc-gen-go-grpc - which protoc-gen-grpc-gateway - which protoc-gen-openapiv2 # 业务单元测试 unit-tests: stage: test needs: - go-lint - check-dep script: - make test # 代码覆盖率 coverage: stage: test script: - go test ./... -coverprofile=coverage.txt -covermode count - cat coverage.txt # 生成发送测试报告 reports: stage: test needs: - unit-tests - coverage script: - echo \"pass\" # 编译二进制文件 binary-local: stage: build needs: - reports script: - make build artifacts: paths: - build/ expire_in: 24h when: manual allow_failure: false # 发布容器至默认镜像中心 container-registry: stage: build needs: - binary-local script: - source scripts/env - export VERSION=$(cat VERSION) - echo ${CI_REGISTRY_PASSWORD} | docker login ${CI_REGISTRY} -u ${CI_REGISTRY_USER} --password-stdin - /kaniko/executor --dockerfile ${CI_PROJECT_DIR}/Dockerfile --context ${CI_PROJECT_DIR} --destination ${CI_REGISTRY_IMAGE}:${VERSION} # 打成各种安装包，如：tar、rpm、deb release-package: stage: build needs: - binary-local script: - echo \"package tar\" - echo \"package rpm\" - echo \"package deb\" artifacts: paths: - build/ expire_in: 24h # 部署测试环境 env-test: stage: deploy needs: - release-package - container-registry script: - echo \"deploy test\" # 部署准线上环境 env-staging: stage: production needs: - env-test script: - echo \"deploy staging\" # 部署正式环境，手工确认 env-prod: stage: production needs: - env-staging script: - echo \"deploy production\" only: - main when: manual allow_failure: false Pipeline 解析 需提前在 gitlab 仓库内添加以下几个变量值，web 添加地址：${gitlab}/${repository}/-/settings/ci_cd\n变量 说明 示列 CI_REGISTRY 镜像服务地址 https://ccr.ccs.tencentyun.com CI_REGISTRY_IMAGE 容器镜像名称 ccr.ccs.tencentyun.com/opsaid/test1 CI_REGISTRY_USER 镜像服务授权 110110 CI_REGISTRY_PASSWORD 镜像服务授权 password ","categories":"","description":"","excerpt":"简要概述 通过 gitlab ci 服务，进行流水线构建，流水线语法参考。\nPipeline …","ref":"/docs/devops/integration/gitlab/","tags":"","title":"Gitlab"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/devops/integration/","tags":"","title":"持续集成"},{"body":"简要概述 约束生成微服务所依赖的几个公共名称\n内部变量 变量名 中文名 取值范围 示例 描述 CLI_VERSION 工具版本 [0-9].\\d.\\d 0.3.0 生成该模版所使用的 grpc-kit-cli 版本 ORGANIZATION 组织代码 见变量组合 grpc-kit 产品所在的公司或部门 PRODUCT_CODE 产品代码 ^([a-z0-9]){4,}$ opsaid 同一产品使用相同代码，使用单个词 SHORT_NAME 应用短名 ^([a-z0-9]){4,}$ test1 同一产品使用不同短名，使用单个词 API_VERSION 接口版本 v[1-9]+ v1 微服务主接口版本 APPNAME 应用名称 见变量组合 opsaid-test1-v1 xx PROTO_PACKAGE 服务包名 见变量组合 grpc_kit.api.opsaid.test1.v1 x SERVICE_CODE 服务代码 见变量组合 test1.v1.opsaid xx SERVICE_TITLE 服务标题 见变量组合 OpsaidTest1 xx SERVICE_NAME 服务全名 见变量组合 test1.v1.opsaid.api.grpc-kit.com xx 变量组合 变量名 组合格式 APPNAME ${PRODUCT_CODE}-${SHORT_NAME}-${API_VERSION} PROTO_PACKAGE ${ORGANIZATION}.api.${PRODUCT_CODE}.${SHORT_NAME}.${API_VERSION} SERVICE_CODE ${SHORT_NAME}.${API_VERSION}.${PRODUCT_CODE} SERVICE_TITLE ${PRODUCT_CODE}${SHORT_NAME} SERVICE_NAME ${SHORT_NAME}.${API_VERSION}.${PRODUCT_CODE}.${API_GATEWAY} 注意：\n在 “PROTO_PACKAGE” 中，如果变量 “ORGANIZATION” 存在中化线\"-\"，则需转化为下划线\"_\"； 在 “SERVICE_TITLE” 中，变量 “PRODUCT_CODE” 与 “SHORT_NAME” 首字母均大写； ","categories":"","description":"","excerpt":"简要概述 约束生成微服务所依赖的几个公共名称\n内部变量 变量名 中文名 取值范围 示例 描述 CLI_VERSION …","ref":"/docs/spec-api/key-terms/","tags":"","title":"关键术语"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/devops/deployment/","tags":"","title":"服务部署"},{"body":"简要概述 如何通过 proto 编写一个符合相同规范的服务定义。\n示例模版 // 仅支持版本 proto3 syntax = \"proto3\"; // 服务包名称 package grpc_kit.api.opsaid.test1.v1; // 生成的 go 包 option go_package = \"github.com/opsaid/test1/api/opsaid/test1/v1;test1v1\"; // 引入依赖的外部 proto 文件 import \"github.com/grpc-kit/api/known/status/v1/response.proto\"; // 同组 RPC 方法对应一个 proto 文件，以该组 RPC 名称的小写字母为文件名 import \"github.com/opsaid/test1/api/opsaid/test1/v1/demo.proto\"; // 该微服务支持的 RPC 方法定义 service OpsaidTest1 { rpc HealthCheck(grpc_kit.api.known.status.v1.HealthCheckRequest) returns (grpc_kit.api.known.status.v1.HealthCheckResponse) {} rpc Demo(DemoRequest) returns (DemoResponse) {} } 名称规范 proto 包名 格式：\npackage {组织代码}.api.{产品代码}.{应用短名}.{接口版本} 示例：\npackage grpc_kit.api.opsaid.test1.v1; 名称 示例 说明 组织代码 grpc_kit 同一个组织下，如：公司、部门等 产品代码 opsaid 同一个产品体系，如：运维助手 应用短名 test1 同一个产品友好名称，如：告警服务 接口版本 v1 服务接口主版本，微服务在 “0.1.X” 与 “1.X” 均表示为 “v1” go 包名 格式：\noption go_package = \"{引用 pb.go 包地址};{应用短名}{接口版本}\"; 示例：\noption go_package = \"github.com/grpc-kit/pkg/api/known/example/v1;examplev1\"; 名称 示例 说明 引用 pb.go 包地址 github.com/grpc-kit/pkg/api/known/example/v1 不一定是 proto 源文件地址 {应用短名}{接口版本} examplev1 两个组合，中间没有任何分隔符 service 名称 格式：\nservice {产品代码}{应用短名} { ...... } 示例：\nservice OpsaidTest1 { ...... } 名称 示例 说明 {产品代码}{应用短名} OpsaidTest1 两个单词组合，中间无风格符且首字母大写 ","categories":"","description":"","excerpt":"简要概述 如何通过 proto 编写一个符合相同规范的服务定义。\n示例模版 // 仅支持版本 proto3 syntax = …","ref":"/docs/spec-api/service/","tags":"","title":"定义服务"},{"body":"简要概述 向服务发送 API 请求，可能会产生多种不同的错误响应，以下文档将会描述数据结构以及大致的原因。\n响应体结构 查看完整的 proto 文件定义，关键部分如下：\n// ErrorResponse 用于定义统一错误响应体 message ErrorResponse { Status error = 1; } // Status 用于定义统一错误状态码 message Status { int32 code = 1; string status = 2; string message = 3; repeated google.protobuf.Any details = 4; } 一个 json 示例：\n{ \"error\": { \"code\": 5, \"status\": \"NotFound\", \"message\": \"unknown service\", \"details\": [ { \"@type\": \"type.googleapis.com/grpc_kit.api.known.status.v1.TracingRequest\", \"id\": \"b17f76dc51de4098bc974e5f2009c097\" } ] } } 状态码说明 code status http code default message 0 OK 200 No error. 1 Canceled 499 Request cancelled by the client. 2 Unknown 500 Unknown server error. 3 InvalidArgument 400 Client specified an invalid argument. 4 DeadlineExceeded 504 Request deadline exceeded. 5 NotFound 404 A specified resource is not found, or the request is rejected by undisclosed reasons, such as whitelisting. 6 AlreadyExists 409 The resource that a client tried to create already exists. 7 PermissionDenied 403 Client does not have sufficient permission. 8 ResourceExhausted 429 Either out of resource quota or reaching rate limiting. 9 FailedPrecondition 400 Request can not be executed in the current system state, such as deleting a non-empty directory. 10 Aborted 409 Concurrency conflict, such as read-modify-write conflict. 11 OutOfRange 400 Client specified an invalid range. 12 Unimplemented 501 The API method not implemented or enabled by the server. 13 Internal 500 Internal server error. 14 Unavailable 503 Service unavailable. 15 DataLoss 500 Unrecoverable data loss or data corruption. 16 Unauthenticated 401 Request not authenticated due to missing, invalid, or expired OAuth token. 204 NoContent 204 Service is no additional content to send in the response content. ","categories":"","description":"","excerpt":"简要概述 向服务发送 API 请求，可能会产生多种不同的错误响应，以下文档将会描述数据结构以及大致的原因。 …","ref":"/docs/spec-api/error/","tags":"","title":"处理错误"},{"body":"简要概述 描述服务的基础信息。\n配置示例 services: root_path: grpc-kit namespace: example service_code: test1.v1.opsaid api_endpoint: api.grpc-kit.com grpc_address: 0.0.0.0:10081 http_address: 0.0.0.0:10080 数据结构 // ServicesConfig 基础服务配置，用于设定命名空间、注册的路径、监听的地址等 type ServicesConfig struct { RootPath string `mapstructure:\"root_path\"` Namespace string `mapstructure:\"namespace\"` ServiceCode string `mapstructure:\"service_code\"` APIEndpoint string `mapstructure:\"api_endpoint\"` GRPCAddress string `mapstructure:\"grpc_address\"` HTTPAddress string `mapstructure:\"http_address\"` PublicAddress string `mapstructure:\"public_address\"` } 配置参数 名称 类型 说明 root_path string 服务注册的前缀，全局统一，一般同组织代码 namespace string 服务注册的空间，全局统一 service_code string 服务的代码，名称唯一且必填，格式：应用短名.接口版本.产品代码 api_endpoint string 接口网关的地址 grpc_address string 服务所监听的grpc地址（如未设置，自动监听在127.0.0.1的随机端口） http_address string 服务所监听的http地址（如未设置，则不开启gateway服务） public_address string 服务注册，外部网络可连接的grpc地址（一般等同于grpc-address） 应用场景 开启 http 监听 services: service_code: test1.v1.opsaid http_address: 127.0.0.1:8080 grpc_address: 127.0.0.1:10081 启动服务，将会在 127.0.0.1 上的 8080 监听 http 协议请求，这些请求会自动转化为 grpc 协议至 127.0.0.1 的 10081 端口。\n关闭 http 监听 services: service_code: test1.v1.opsaid grpc_address: 127.0.0.1:10081 启动服务，将仅在 127.0.0.1:10081 端口监听 grpc 协议。\n使用 TLS 加密 gRPC 或 HTTP 连接 本地 HTTP Server 手工配置 TLS 证书 services: # http 服务配置 http_service: enabled: true address: 127.0.0.1:8080 # 手工配置服务端证书，优先级低于 tls_auto tls_server: cert_file: \"./config/tls/http.crt\" key_file: \"./config/tls/http.key\" 本地 HTTP Server 自动配置 TLS 证书 services: # http 服务配置 http_service: enabled: true address: 127.0.0.1:8080 # 通过 acme 自动申请服务端证书，优先级高于 tls_server tls_auto: acme: email: \"support@grpc-kit.com\" cache_dir: \"./config/tls/\" domains: - test.grpc-kit.com - demo.grpc-kit.com 域名需解析到公网 IP 上，而且应用必须可通过该 IP 访问到。这里自动化证书通过 TLS-ALPN-01 实现。\n本地 GRPC Service 使用单向 TLS 证书 services: # grpc 服务配置 grpc_service: enabled: true address: 127.0.0.1:10081 tls_server: cert_file: \"./config/tls/grpc-server.crt\" key_file: \"./config/tls/grpc-server.key\" # http 服务配置 http_service: tls_server: ca_file: \"./config/tls/grpc-server-ca.crt\" 客户端配置了 grpc 服务端的 ca 用于验证服务端连接是否合法有效性。\n本地 GRPC Service 使用双向 mTLS 证书 services: # grpc 服务配置 grpc_service: enabled: true address: 127.0.0.1:10081 # 如果配置了 mTLS 也需要在 http_service.tls_client 加上相应证书，否则 http 转 grpc 接口不可用 tls_server: cert_file: \"./config/tls/grpc-server.crt\" key_file: \"./config/tls/grpc-server.key\" ca_file: \"./config/tls/grpc-client-ca.crt\" # http 服务配置 http_service: tls_server: ca_file: \"./config/tls/grpc-server-ca.crt\" cert_file: \"./config/tls/grpc-client.crt\" key_file: \"./config/tls/grpc-client.key\" 对于使用 mTLS 两边的证书可以来不不同的 ca 签发。\n通过 openssl 生成证书 创建 ca cat \u003e ca-csr.conf \u003c\u003c EOF [ req ] default_bits = 2048 prompt = no default_md = sha256 distinguished_name = dn [ dn ] C = CN CN = demo-ca [ v3_ext ] basicConstraints=critical,CA:true,pathlen:1 keyUsage=critical,digitalSignature,keyCertSign,cRLSign EOF openssl genrsa -out ca.key 2048 openssl req -new -key ca.key -out ca.csr -config ca-csr.conf openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt -days 3650 -extensions v3_ext -extfile ca-csr.conf 创建 http 服务证书 cat \u003e ca-csr.conf \u003c\u003c EOF [ req ] default_bits = 2048 prompt = no default_md = sha256 req_extensions = req_ext distinguished_name = dn [ dn ] C = CN CN = http [ req_ext ] subjectAltName = @alt_names [ alt_names ] IP.1 = 127.0.0.1 IP.2 = 10.5.39.39 DNS.1 = localhost DNS.2 = opsaid-test6-v1.default.svc [ v3_ext ] authorityKeyIdentifier=keyid,issuer:always basicConstraints=CA:FALSE keyUsage=critical,digitalSignature,keyEncipherment extendedKeyUsage=serverAuth subjectAltName=@alt_names EOF openssl genrsa -out http.key 2048 openssl req -new -key http.key -out http.csr -config http-csr.conf openssl x509 -req -in http.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out http.crt -days 3650 -extensions v3_ext -extfile http-csr.conf 其中 grpc 服务证书方法同 http，以上 “*-csr.conf” 文件内容根据实际情况做更改。\n","categories":"","description":"","excerpt":"简要概述 描述服务的基础信息。\n配置示例 services: root_path: grpc-kit namespace: example …","ref":"/docs/spec-cfg/services/","tags":"","title":"基础服务"},{"body":"flowchart TD A([开始]) --\u003e A1[主分支 main]; A([开始]) --\u003e A2[开发分支 develop]; Z([结束]) A2 --\u003e A21[新增功能需求: 创建功能分支 feature-XXX]; A21 --\u003e A22{新开发功能是否完成}; A22 --\u003e |是| A221[提交代码执行 CI 阶段]; A221 --\u003e A2211{Runner: 自动化构建与测试案例是否通过}; A2211 --\u003e |是| A22111[从 develop 合并代码并删除 feature-XXX 分支]; A2211 --\u003e |否| A222; A22 --\u003e |否| A222[继续开发自测完成后提交代码]; A222 --\u003e A221; A22111 --\u003e Z; A2 --\u003e A31[累计功能发布: 创建发布分支 release-X.Y]; A31 --\u003e A311{是否已存在 release-X.Y 分支}; A311 --\u003e |是| A3111[从 develop 合并最新代码]; A311 --\u003e |否| A3112[从 develop 创建最新分支]; A3111 --\u003e A3113[监听合并或创建事件 触发CICD阶段]; A3112 --\u003e A3113; A3113 --\u003e A31131{Runner: 自动化构建与测试案例是否通过}; A31131 --\u003e |是| A311311[合并至 develop 分支]; A311311 --\u003e A3113112[合并至 main 分支]; A31131 --\u003e |否| A311312[在 release-X.Y 分支修复异常提交代码]; A311312 --\u003e A3113; A3113112 --\u003e Z; A1 --\u003e A12[来自 release-X.Y 或 hotfix-XXX 的合并请求]; A12 --\u003e A121{管理员确认是否允许}; A121 --\u003e |是| A1211[确认合并]; A121 --\u003e |否| A1212[拒绝合并]; A1212 --\u003e A311312; A1211 --\u003e A13[提交标签 git tag vX.Y.Z]; A13 --\u003e A131[使用 release-X.Y 或 hotfix-XXX 阶段构建的镜像进行部署]; A131 --\u003e A1311{Runner: 自动化部署是否通过}; A1311 --\u003e |是| Z; A1311 --\u003e |否| A311312; A1 --\u003e A11[线上环境发现BUG]; A11 --\u003e A111{确认为BUG是否需修复}; A111 --\u003e |是| A1111[从 main 仓库创建 hotfix-XXX 分支]; A111 --\u003e |否| Z; A1111 --\u003e A112[仅修复BUG代码不涉及任何功能新增]; A112 --\u003e A1121[提交代码在 hotfix-XXX 分支]; A1121 --\u003e A11211{Runner: 自动化构建与测试案例是否通过}; A11211 --\u003e |是| A112111[构建提交容器镜像]; A11211 --\u003e |否| A1121; A112111 --\u003e A11212[合并至 develop 与 main 分支]; A11212 --\u003e A11213[删除 hotfix-XXX 分支]; A11213 --\u003e A12; ","categories":"","description":"","excerpt":"flowchart TD A([开始]) --\u003e A1[主分支 main]; A([开始]) --\u003e A2[开发分支 develop]; …","ref":"/docs/spec-dev/flows/git-flow/","tags":"","title":"Git Flow"},{"body":"简要概述 高效的持续交付体系，必须需要一个合适的代码分支管理策略，主要有：主干开发、特性分支开发。\n只能根据不通的业务场景选择最适合的策略。\n主干开发 开发者在主分支提交代码，发布版本时创建版本发布分支。\n优点：\n集成频繁效率高； 无需在多个分支之间切； 仅包含：主分支、版本分支； 缺点：\n可能出现某个人的代码失误而影响全局； 需要在代码运行期间使用特性切换加速开发； 特性分支开发 需要新增特性时，开发者从主干分支克隆特性分支，仅允许在该分支直接提交代码，待功能完成之后合并至主分支，常见的模型有：git flow、github flow、gitlab flow 三种模型。\nGit Flow 该模型是在2010年构想出来的，在这十几年里，已经被许多软件团队使用，以至于部分开发者将其视为某种标准。\n在使用会涉及到较繁琐的流程，很多团队新人还需额外时间学习才能融入业务开发，反而降低了效率。\n分支功能描述：\n名称 功能 生命周期 代码稳定 权限 main 主分支 长期 是 仅允许开发负责人且只能从 release 分支合并，tag 只能从 main 分支标记 develop 开发分支 长期 是 不允许直接提交，只能由开发负责人且只能从 feature 分支合并 release-X.Y 发布分支 长期 是 不允许直接提交，仅允许从 develop 分支合并 feature-XYZ 功能分支 合并后删除 否 开发可直接提交代码，必须从 develop 分支创建出来 hotfix-XYZ 补丁分支 合并后删除 否 开发可直接提交代码，比较急的异常，直接从 main 分支创建，完成后必须合并至 main 与 develop 分支 查看分支流程。\n查看规范出处。\nGitHub Flow 仅包含主分支与特性分支。\n相比 Git Flow 简化了流程，开发者接收需求并创建独立的特性分支，完成后则发起 “Pull requests” 请求合并，待在其他人审阅并签署确认后由专人合并到主分支，最后删除特性分支。\n名称 功能 生命周期 代码稳定 权限 main 主分支 长期 是 不允许直接提交代码，仅允许负责人合并来自其他分支 feat-X 特性分支 合并后删除 否 由开发人员控制，必须包含完整的文档与测试案例 查看分支流程。\n查看规范出处。\nGitLab Flow https://docs.gitlab.com/ee/topics/gitlab_flow.html\n","categories":"","description":"","excerpt":"简要概述 高效的持续交付体系，必须需要一个合适的代码分支管理策略，主要有：主干开发、特性分支开发。\n只能根据不通的业务场景选择最适合的策略。 …","ref":"/docs/spec-dev/git-branch/","tags":"","title":"分支管理"},{"body":"简要概述 通过在本机安装 go、protoc、protoc-gen-go、protoc-gen-go-grpc、protoc-gen-grpc-gateway、protoc-gen-openapiv2 等编译依赖的组件。\n目前推荐使用本地环境进行应用模版创建、编译。\n基础环境 go 版本安装 版本必须大于等于1.18.x，版本检查：\ngo version centos 7 安装方式：\nyum install -y epel-release.noarch yum install -y golang.x86_64 macOS 安装方式：\nbrew install go 设置全局变量 应用运行均依赖 “GOPATH” 与 “GO111MODULE”，所以必须确保正确设置了该变量。\n# 开启 go mod export GO111MODULE=on # 根据实际情况是否需要设置 proxy export GOPROXY=\"https://goproxy.cn\" # GOPATH 仅做示例，根据实际情况更改 export GOPATH=$HOME/go # 添加 $GOPATH/bin 目录下二进制文件可被 shell 查询 export PATH=$PATH:$HOME/bin:$GOPATH/bin 请确保以上变量在系统全局生效，可以写入 “\"$HOME/.bash_profile” 或 “$HOME/.zshrc” 等。\n安装 grpc-kit-cli 至 https://github.com/grpc-kit/cli/releases 选择最新版本，根据目标系统架构下载。\n目前支持以下架构：\nmacOS intel x86_64 macOS apple m linux x86_64 linux arm64 安装 protoc 插件 手工安装 protoc 或者通过通过-make-下载依赖。\n使用 protoc 版本 v21.12，根据不同系统选择下载地址：\nhttps://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-linux-x86_64.zip https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-linux-aarch_64.zip https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-osx-aarch_64.zip https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-osx-x86_64.zip Linux x86_64 系统安装 protoc 选择，示例：\ncd /tmp curl -L -O 'https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-linux-x86_64.zip' unzip protoc-21.12-linux-x86_64.zip # 相关二进制存放 GOPATH/bin 目录下 mv bin/protoc $GOPATH/bin/ # 对 protoc 公知类型移动至 /usr/local/include 目录下 mv include/google /usr/local/include/ # 清理移除垃圾数据 rmdir bin/ include/ 特别的，对于 macOS apple 芯片选择 v21.12 的 aarch 架构版本，如：\nprotoc-3.19.3-linux-aarch_64.zip curl -L -O 'https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-osx-aarch_64.zip' 对于 linux arm 选择 v21.12 的 aarch 架构版本，如：\nhttps://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-linux-aarch_64.zip 手工安装 protoc-gen-X 或者通过通过-make-下载依赖。\nprotoc-gen-go、protoc-gen-go-grpc、protoc-gen-grpc-gateway、protoc-gen-openapiv2 各版本安装，会自动拷贝二进制至 “$GOPATH/bin” 下面：\ngo install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2 go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28 go install github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway@v2.15.2 go install github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2@v2.15.2 手工安装依赖的 proto 文件 或者通过通过-make-下载依赖。\ngit clone -b v0.3.0 --depth 1 https://github.com/grpc-kit/api.git $GOPATH/src/github.com/grpc-kit/api git clone --depth 1 https://github.com/googleapis/googleapis.git $GOPATH/src/github.com/googleapis/googleapis git clone -b v2.15.2 --depth 1 https://github.com/grpc-ecosystem/grpc-gateway.git $GOPATH/src/github.com/grpc-ecosystem/grpc-gateway 手工安装 grpc-kit-cli 二进制 可通过以下两种方式进行\n下载二进制安装 https://github.com/grpc-kit/cli/releases 源码编译安装 git clone https://github.com/grpc-kit/cli.git make build cp ./build/grpc-kit-cli-* /usr/local/bin/grpc-kit-cli 生成应用的模版 生成代码模版\nmkdir -p $GOPATH/src/github.com/opsaid cd $GOPATH/src/github.com/opsaid ./grpc-kit-cli new -t service -o grpc-kit -p opsaid -s test1 --git-domain github.com 通过 make 下载依赖 make protoc make protoc-gen-go make protoc-gen-go-grpc make protoc-gen-grpc-gateway make protoc-gen-openapiv2 取保 $GOPATH/bin 目录在 $PATH 里面。\n服务访问测试 运行微服务代码 make run 微服务接口文档 http://127.0.0.1:8080/openapi-spec/ 微服务编译版本 # curl http://127.0.0.1:8080/version | python -m json.tool { \"appname\": \"test1.v1.opsaid\", \"build_date\": \"2023-01-13T09:10:45Z\", \"git_commit\": \"1234567890123456789012345678901234567890\", \"git_branch\": \"\", \"go_version\": \"go1.18.5\", \"compiler\": \"gc\", \"platform\": \"darwin/amd64\", \"cli_version\": \"0.2.3\", \"commit_unix_time\": 0, \"release_version\": \"0.1.0\" } 微服务性能数据 # curl http://127.0.0.1:8080/metrics # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 0.000114581 go_gc_duration_seconds{quantile=\"0.25\"} 0.000873528 go_gc_duration_seconds{quantile=\"0.5\"} 0.002296699 go_gc_duration_seconds{quantile=\"0.75\"} 0.003722618 go_gc_duration_seconds{quantile=\"1\"} 0.010592338 go_gc_duration_seconds_sum 0.033207328 go_gc_duration_seconds_count 12 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 19 ... 微服务健康探测 探测流量仅到 gateway 不会调度到 grpc 服务。\n# curl http://127.0.0.1:8080/ping OK 探测流量同时到 gateway 与 grpc 服务。\n# curl 'http://127.0.0.1:8080/healthz?service=test1.v1.opsaid' {\"status\":\"SERVING\"} 示例 demo 接口 # curl -u user1:grpc-kit-cli http://127.0.0.1:8080/api/demo ","categories":"","description":"","excerpt":"简要概述 通过在本机安装 go、protoc、protoc-gen-go、protoc-gen-go-grpc、protoc-gen-grp …","ref":"/docs/overview/local/","tags":"","title":"本机环境"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/overview/","tags":"","title":"快速开始"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/concepts/grpc/","tags":"","title":"gRPC"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/concepts/","tags":"","title":"核心组件"},{"body":"简要概述 通过 github action 服务，进行流水线构建，流水线语法参考。\nPipeline 模版 .github/workflows/grpc-kit.yml ","categories":"","description":"","excerpt":"简要概述 通过 github action 服务，进行流水线构建，流水线语法参考。\nPipeline …","ref":"/docs/devops/integration/github/","tags":"","title":"Github"},{"body":" gitGraph commit commit branch increase-test-timeout commit commit checkout main merge increase-test-timeout commit branch add-code-of-conduct commit commit checkout main merge add-code-of-conduct commit ","categories":"","description":"","excerpt":" gitGraph commit commit branch increase-test-timeout commit commit …","ref":"/docs/spec-dev/flows/github-flow/","tags":"","title":"Github Flow"},{"body":"简要概述 用于规范项目代码提交日志，这里借鉴 Angular 规则，规范化的提交记录，有以下好处：\n快速查找历史变更信息； 自动化生成 CHANGELOG.md 文档； 提交规范 各个 git commit 提交记录，由：header、body、footer 三部分组成，格式如下：\n\u003cheader\u003e // 空一行 \u003cbody\u003e // 空一行 \u003cfooter\u003e 其中 header 是强制填写，由以下三部分组成：\n\u003ctype\u003e(\u003cscope\u003e): \u003cshort summary\u003e │ │ │ │ │ └─⫸ 本次变更内容的一句话总结，中文或小写英文，末尾不带句号 │ │ │ └─⫸ 涉及变更的主要模块，如：cli|pkg|api │ └─⫸ 本次提交功能变更的类型，如：feat|fix|docs|perf|refactor|test 参数详解 header type type 说明 feat 涉及业务代码变更，添加新功能 fix 涉及业务代码变更，修复已知BUG perf 涉及业务代码变更，优化功能性能、体验等 refactor 涉及业务代码变更，但不属于 feat、fix、perf 的类型 ci 仅涉及流水线变更，如：gitlab-ci、github action 的 yaml 文件 docs 仅涉及文档类变更，如：README.md 或 代码注释 等 release 仅涉及版本号变更，如：VERSION、CHANGELOG.md 中关联的值 test 仅涉及测试代码变更，如：hello_test.go build 仅涉及构建编译依赖的组件版本等变更，如：go.mod chore 其他琐碎的变更，但对代码功能没有影响，比如删除了无用的代码、注释等清理操作 scope 代码变更的模块，如：cli、pkg、api 等，这块为可选，非必填内容。\nsummary 编写一个具有概括性简短的描述\n不超过 50 个字符 可选择编写中文或英文 英文统一小写，首字母不大写 英文专业术语除外，如：Makefile 末尾不带任何标点符号 示例：\nfeat(cli): 在 Makefile 中添加容器化构建应用 release: cut the 0.2.4-beta.1 docs: release notes for the 0.2.4-beta.1 body 解释此次变更的详细描述，可由多行组成，格式准守 “Markdown” 语法。\nfooter 仅在两种情况下才会使用：\n不兼容的更改 如果当前代码提交之后，会对上一个版本不兼容，则必须以 BREAKING CHANGE 开头，后面在添加详细描述。\nBREAKING CHANGE: \u003cbreaking change summary\u003e \u003cBLANK LINE\u003e \u003cbreaking change description + migration instructions\u003e \u003cBLANK LINE\u003e \u003cBLANK LINE\u003e Fixes #\u003cissue number\u003e 关闭 issue 如果当前提交是针对某个 “issue”，那么可以以 Closes # 加问题编号。\n已经废弃的功能 DEPRECATED: \u003cwhat is deprecated\u003e \u003cBLANK LINE\u003e \u003cdeprecation description + recommended update path\u003e \u003cBLANK LINE\u003e \u003cBLANK LINE\u003e Closes #\u003cpr number\u003e 相关示例 查看历史变更记录 git log HEAD --pretty=format:%s ","categories":"","description":"","excerpt":"简要概述 用于规范项目代码提交日志，这里借鉴 Angular 规则，规范化的提交记录，有以下好处：\n快速查找历史变更信息； …","ref":"/docs/spec-dev/git-commit/","tags":"","title":"提交日志"},{"body":"简要概述 通过容器环境，快速创建应用模版并编译、运行。相对于本地环境，这样无需在开发机器安装各种依赖的组件，但目前容器环境还存在部分问题，推荐使用本地环境。\n生成代码并运行 创建应用模版 docker run \\ --rm \\ -v $(pwd):/usr/local/src \\ -w /usr/local/src \\ registry.cn-hangzhou.aliyuncs.com/grpc-kit/cli:0.2.4-beta.1 \\ grpc-kit-cli new -t service -p opsaid -s test1 运行应用代码 docker run -i -t --rm \\ -v $GOPATH/pkg:/go/pkg \\ -v $(pwd):/usr/local/src \\ -w /usr/local/src \\ --network host \\ registry.cn-hangzhou.aliyuncs.com/grpc-kit/cli:0.2.4-beta.1 \\ make run 服务访问测试 参考本地环境。\n","categories":"","description":"","excerpt":"简要概述 通过容器环境，快速创建应用模版并编译、运行。相对于本地环境，这样无需在开发机器安装各种依赖的组件，但目前容器环境还存在部分问题，推 …","ref":"/docs/overview/docker/","tags":"","title":"容器环境"},{"body":"简要概述 通过 jenkins 服务，进行流水线构建，流水线语法参考。\nPipeline 模版 文件路径 .jenkins/workflows/Jenkinsfile 模版内容 pipeline { agent { kubernetes { // TODO；目标集群，由系统管理员确认 cloud 'dev' // TODO；继承目标集群的模版 inheritFrom 'grpc' defaultContainer 'build' } } parameters { booleanParam(name: 'CI_BIZ_CODE_BUILD', defaultValue: true, description: '是否构建镜像，取消则直接至 k8s yaml 更新') booleanParam(name: 'CI_PIPELINE_SILENCE', defaultValue: false, description: '执行流水线全程静默无需二次确认') choice(name: 'CI_REGISTRY_HOSTNAME', choices: ['ccr.ccs.tencentyun.com'], description: '支持的镜像中心列表') choice(name: 'CI_REGISTRY_NAMESPACE', choices: ['opsaid'], description: '支持的镜像中心列表') choice(name: 'DEPLOY_ENV', choices: ['dev', 'test', 'staging', 'prod'], description: '应用部署到具体的环境') } environment { BUILD_ENV = \"remote\" GOPROXY = \"https://goproxy.cn\" CI_BIZ_BRANCH_NAME = \"main\" CI_BIZ_GROUP_APPID = \"opsaid\" CI_BIZ_REPO_URL = \"https://github.com/opsaid/test1.git\" CI_OPS_REPO_URL = \"https://github.com/opsaid/test1.git\" CI_BIZ_REPO_AUTH = \"biz-group-appid-${CI_BIZ_GROUP_APPID}\" CI_OPS_REPO_AUTH = \"biz-group-appid-${CI_BIZ_GROUP_APPID}\" KUBERNETES_LABEL_PREFIX = \"api.grpc-kit.com\" KUBERNETES_NAMESPACE = \"biz-${DEPLOY_ENV}-${CI_BIZ_GROUP_APPID}\" KUBERNETES_PM2_UUID = \"00000000-0000-0000-0000-000000000000\" KUBERNETES_YAML_DIRECTORY = \"deploy/kubernetes/${DEPLOY_ENV}/\" KUBERNETES_CLUSTER_DOMAIN = \"api.grpc-kit.com\" } options { disableConcurrentBuilds(abortPrevious: true) disableResume() timeout(time: 1, unit: 'HOURS') } stages { stage('Prepare') { when { environment name: 'CI_BIZ_CODE_BUILD', value: 'true' } steps { checkout scmGit( branches: [ [name: CI_BIZ_BRANCH_NAME] ], extensions: [ [$class: 'RelativeTargetDirectory', relativeTargetDir: 'source'] ], userRemoteConfigs: [ [ credentialsId: CI_BIZ_REPO_AUTH, url: CI_BIZ_REPO_URL ] ] ) // 执行代码检查 sh ''' cd source make protoc make lint ''' } } stage('Test') { when { environment name: 'CI_BIZ_CODE_BUILD', value: 'true' } steps { // 执行单元测试等 sh ''' cd source make test ''' } } stage('Build') { when { environment name: 'CI_BIZ_CODE_BUILD', value: 'true' } steps { // 选择特定语言容器，执行代码编译 container('build') { sh ''' cd source make build make manifests TEMPLATES=dockerfile make manifests TEMPLATES=kubernetes TEMPLATE_PATH=../gitops/${KUBERNETES_YAML_DIRECTORY} ''' } // 选择 kaniko 容器，执行构建镜像并上传 container('kaniko') { sh ''' cd source ./scripts/kaniko.sh ''' } } } stage('Confirm') { when { environment name: 'CI_PIPELINE_SILENCE', value: 'false' } steps { container('kcli') { sh ''' cd gitops/${KUBERNETES_YAML_DIRECTORY} cat kustomization.yaml ''' } input \"请查看配置，确认是否可以部署？\" } } stage('Production') { steps { container('kcli') { withCredentials([gitUsernamePassword(credentialsId: CI_OPS_REPO_AUTH, gitToolName: 'git-tool')]) { wrap([$class: 'BuildUser']) { sh ''' cd gitops/ ./scripts/kcli.sh commit ''' } sh ''' cd gitops/ ./scripts/kcli.sh apply ''' } } } } } post { always { // TODO；根据实际情况调用接口推送通知 echo \"Send notifications for result: ${currentBuild.result}\" } } } Pipeline 解析 ","categories":"","description":"","excerpt":"简要概述 通过 jenkins 服务，进行流水线构建，流水线语法参考。\nPipeline …","ref":"/docs/devops/integration/jenkins/","tags":"","title":"Jenkins"},{"body":"简要概述 认证、鉴权。\n配置示例 security: enable: true authentication: insecure_rpcs: - SearchHosts oidc_provider: issuer: https://accounts.example.com config: client_id: example supported_signing_algs: - RS256 skip_client_id_check: true skip_expiry_check: false skip_issuer_check: true insecure_skip_verify: true http_users: - username: user1 password: pass1 groups: - sysadmin authorization: allowed_groups: - sysadmin 配置参数 Security 名称 类型 说明 enable bool 是否开启认证、鉴权 authentication Authentication 用户认证，也就是当前是谁在登录 authorization Authorization 用户鉴权，也就是当前登录用户是否有权限操作对应资源 Authentication 名称 类型 说明 insecure_rpcs []string 对应 gRPC 的方法，可以跳过认证 oidc_provider OIDCProvider OIDC 相关配置 http_users []BasicAuth 用户密码列表 OIDCProvider 名称 类型 说明 issuer string oidc 提供者 config OIDCConfig oidc 配置 OIDCConfig 名称 类型 说明 client_id string 用于验证 token.aud 是否与 client_id 相等 supported_signing_algs []string 服务端允许 token 的签名算法类型 skip_client_id_check bool 忽略 token.aud 与client_id 的验证 skip_expiry_check bool 忽略 token 是否过期的验证 skip_issuer_check bool 忽略 token issuer 的验证 insecure_skip_verify bool 忽略 issuer 的ca验证 BasicAuth 名称 类型 说明 username string 用户名 password string 用户 secret_key groups []string 用户归属组 Authorization 名称 类型 说明 allowed_groups []string 所有请求至该服务端的用户必须至少属于一个组内 opa_native OPANative 内置鉴权功能 opa_external OPAExternal 获取外部 opa bundle 鉴权策略 opa_envoy_plugin OPAEnvoyPlugin 连接外部 opa-envoy-plugin 服务鉴权 OPANative 名称 类型 说明 enabled bool 是否开启该鉴权服务 policy Policy 本地策略文件 “auth.rego” 与 “data.yaml” 路径 Policy 名称 类型 说明 auth_file string 为空，则默认使用内嵌 “internal/security/auth.rego” 源代码 data_file string 为空，则默认使用内嵌 “internal/security/data.yaml” 源代码 OPAExternal 名称 类型 说明 enabled bool 是否开启该鉴权服务 config string 对应 open policy agent 配置文件内容 OPAEnvoyPlugin 名称 类型 说明 enabled bool 是否开启该鉴权服务 service Service 插件配置内容 Service 名称 类型 说明 grpc_address string 对应 opa-envoy-plugin 服务地址 使用场景 允许所有请求 security: enable: false 服务端允许所有接口请求，均以匿名用户，也就是关闭认证鉴权。\nHTTP Basic 用户 security: enable: true authentication: http_users: - username: user1 password: pass1 - username: user2 password: pass2 开启服务端接口验证，通过 HTTP Basic Auth 方式，允许用户 “user1:pass1” 或 “user2:pass2” 发起请求通过认证。\n忽略特定 RPC 验证 security: enable: true authentication: insecure_rpcs: - Demo - HealthCheck http_users: - username: user1 password: pass1 开启服务端接口认证，但是忽略 “Demo” 与 “HealthCheck” 两个 gRPC 方法的检查，这个还是被鉴权策略约束。\n开启 Tokne 支持 HS256 签名 security: enable: true authentication: oidc_provider: issuer: https://accounts.example.com config: supported_signing_algs: - HS256 skip_issuer_check: true insecure_skip_verify: true http_users: - username: user1 password: pass1 支持客户端 Token 是以 HS256 签名算法，其中 “token.sub” 为 “user1” 并使用 “pass1” 为密钥做签名。\n注意：这种签名的 token 不会传递给所配置的 oidc 服务提供验证，而是替换使用本地配置的 http basic 用户所对应的密码作为 token 的签名密钥\n仅允许特定用户组访问 security: enable: true authentication: oidc_provider: issuer: https://accounts.example.com config: skip_issuer_check: true insecure_skip_verify: true http_users: - username: user1 password: pass1 groups: - sysadmin - username: user2 password: pass2 groups: - guest authorization: allowed_groups: - sysadmin 则该服务仅可被属于 “sysadmin” 用户组的用户访问，使用 “http basic” 既仅 “user1”。\n如果使用 “oidc” 当前仅但 “jwt” 中包含 “groups” 属性且存在 “sysadmin” 用户组用户。\n使用应用本地鉴权策略 # 认证鉴权配置 security: enable: true # 认证：谁在登录 authentication: http_users: - username: user1 password: pass1 groups: - sysadmin # 鉴权：能做什么 authorization: # 内置权限规则，通过本地配置文件管理 opa_native: enabled: true #policy: # 未配置则为 internal/security/auth.rego 内嵌文件 #auth_file: \"./config/auth.rego\" # 未配置则为 internal/security/data.yaml 内嵌文件 #data_file: \"./config/data.yaml\" 如果未配置 “security.authorization.opa_native.policy.auth_file” 参数，则服务在编译时会使用源代码路径下 “internal/security/auth.rego” 内容，并在编译时嵌入至应用二进制内。如果配置则需保证文件存在，同时策略文件独立于应用程序。\n同理，如果未配置 “security.authorization.opa_native.policy.data_file” 参数，则服务在编译时会使用源代码路径下 “internal/security/data.yaml” 内容，并在编译时嵌入至应用二进制内。如果配置则需保证文件存在，同时策略文件独立于应用程序。\n使用外部鉴权策略文件 # 认证鉴权配置 security: enable: true # 认证：谁在登录 authentication: http_users: - username: user1 password: pass1 groups: - sysadmin # 鉴权：能做什么 authorization: # 权限规则由外部管理，如更改权限本地实时生效，无需重启服务 opa_external: enabled: true # 配置内容见：https://www.openpolicyagent.org/docs/latest/configuration/ config: | services: test: url: http://192.168.0.2:8080 bundles: test: resource: /bundle.tar.gz decision_logs: console: false 以上配置说明在服务启动时，会从 “http://192.168.0.2:8080/bundle.tar.gz” 下载权限规则并加载至应用内。\n使用外部 opa-envoy-plugin 服务 # 认证鉴权配置 security: enable: true # 认证：谁在登录 authentication: http_users: - username: user1 password: pass1 groups: - sysadmin # 鉴权：能做什么 authorization: # 通过把数据提交至 opa-envoy-plugin 服务，由它进行判断功能 opa_envoy_plugin: enabled: true service: grpc_address: 192.168.0.1:9191 这个同 envoy ext_authz 插件。\n每次鉴权时，均需连接 “grpc_address” 地址做个判断，如果服务故障则会拒绝连接请求。\n多个鉴权服务同时使用 security: enable: true authentication: oidc_provider: issuer: https://accounts.example.com config: skip_issuer_check: true insecure_skip_verify: true http_users: - username: user1 password: pass1 groups: - sysadmin - username: user2 password: pass2 groups: - guest authorization: allowed_groups: - sysadmin opa_native: enabled: true ...... opa_external: enabled: true ...... opa_envoy_plugin: enabled: true ...... 如果同时启用了 “allowed_groups”、“opa_native”、“opa_external”、“opa_envoy_plugin” 鉴权功能，则一个请求必须同时满足以上才可被允许访问。\n","categories":"","description":"","excerpt":"简要概述 认证、鉴权。\n配置示例 security: enable: true authentication: insecure_rpcs: …","ref":"/docs/spec-cfg/security/","tags":"","title":"认证鉴权"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/spec-cfg/","tags":"","title":"配置规范"},{"body":" 用于规范开发流程，关键在于工作的流程\n","categories":"","description":"","excerpt":" 用于规范开发流程，关键在于工作的流程\n","ref":"/docs/spec-dev/","tags":"","title":"开发规范"},{"body":"简要概述 对在 go 语言下使用 grpc 的快速入门。\n环境准备 编译器安装 Go 语言 环境安装； Protocol buffer 编译器 protoc 安装； 生成 go 语言 protocol buffer 插件： protoc-gen-go 消息序列化生成器安装； protoc-gen-go-grpc gRPC 服务生成器安装； Go Protobuf 插件 在 Go 的 Protobuf 生态中，protoc-gen-go 与 protoc-gen-go-grpc 也经历了一段历史演进：\n时期 代码生成方式 特点 v1.20 前 单一protoc-gen-go 同时生成消息和 gRPC 代码 v1.20+ 拆分为两个独立插件 分离核心消息与 gRPC 服务生成逻辑 在新版本后依赖关系图解：\ngraph LR Proto[.proto文件] --\u003e|protoc-gen-go| Messages[消息结构.pb.go] Proto --\u003e|protoc-gen-go-grpc| Service[gRPC服务_grpc.pb.go] Service --\u003e|依赖| Messages Service --\u003e|依赖| grpc[google.golang.org/grpc] 它们的职责和生成内容分工：\n1. protoc-gen-go：消息序列化生成器\n核心职责 生成Protobuf消息结构将.proto文件中定义的message转换为Go结构体 实现编解码接口生成Marshal/Unmarshal等序列化方法 字段访问器生成为可选字段生成GetXXX()方法 枚举映射转换Protobuf枚举类型为Go的const枚举 生成文件示例 “helloworld.pb.go” type HelloRequest struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Greeting string `protobuf:\"bytes,1,opt,name=greeting,proto3\" json:\"greeting,omitempty\"` } func (x *HelloRequest) Reset() { *x = HelloRequest{} if protoimpl.UnsafeEnabled { mi := \u0026file_helloworld_helloworld_proto_msgTypes[0] ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x)) ms.StoreMessageInfo(mi) } } func (x *HelloRequest) String() string { return protoimpl.X.MessageStringOf(x) } func (*HelloRequest) ProtoMessage() {} 2. protoc-gen-go-grpc：gRPC 服务生成器\n核心职责 生成服务接口：转换 .proto 中的 service 定义 创建客户端存根：生成可调用的客户端方法 生成服务端骨架：提供需实现的服务接口 注册方法生成：生成服务注册函数 RegisterXXXServer 生成文件示例 “helloworld_grpc.pb.go” // 客户端存根 // HelloServiceClient is the client API for HelloService service. // // For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream. type HelloServiceClient interface { SayHello(ctx context.Context, in *HelloRequest, opts ...grpc.CallOption) (*HelloResponse, error) } type helloServiceClient struct { cc grpc.ClientConnInterface } func NewHelloServiceClient(cc grpc.ClientConnInterface) HelloServiceClient { return \u0026helloServiceClient{cc} } ...... // 服务端接口 // HelloServiceServer is the server API for HelloService service. // All implementations must embed UnimplementedHelloServiceServer // for forward compatibility type HelloServiceServer interface { SayHello(context.Context, *HelloRequest) (*HelloResponse, error) mustEmbedUnimplementedHelloServiceServer() } // UnimplementedHelloServiceServer must be embedded to have forward compatible implementations. type UnimplementedHelloServiceServer struct { } func (UnimplementedHelloServiceServer) SayHello(context.Context, *HelloRequest) (*HelloResponse, error) { return nil, status.Errorf(codes.Unimplemented, \"method SayHello not implemented\") } // 注册方法 func RegisterHelloServiceServer(s grpc.ServiceRegistrar, srv HelloServiceServer) { s.RegisterService(\u0026HelloService_ServiceDesc, srv) } 3. 典型编译命令\n# 同时安装两个生成器 go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 开始 gRPC 服务 通过 proto 语言定义 编写 “helloworld/helloworld.proto” 文件内容：\n$ mkdir helloworld $ vim helloworld/helloworld.proto syntax = \"proto3\"; package default; option go_package = \"default/helloworld\"; service HelloService { rpc SayHello (HelloRequest) returns (HelloResponse); } message HelloRequest { string greeting = 1; } message HelloResponse { string reply = 1; } 通过 protoc 工具编译 仅生成消息体 protoc \\ --go_out=. \\ --go_opt=paths=source_relative \\ helloworld/helloworld.proto 编译生成 “helloworld/helloworld.pb.go” 文件。\n仅生成服务体 protoc \\ --go-grpc_out=. \\ --go-grpc_opt=paths=source_relative \\ helloworld/helloworld.proto 编译生成 “helloworld/helloworld_grpc.pb.go” 文件。\n或一次性生成两种代码 protoc \\ --go_out=. \\ --go_opt=paths=source_relative \\ --go-grpc_out=. \\ --go-grpc_opt=paths=source_relative \\ helloworld/helloworld.proto 开发场景选择\n关注点分离：protoc-gen-go 专注数据表示，protoc-gen-go-grpc 专注通信逻辑； 版本兼容：需确保两者版本匹配（推荐使用最新稳定版）； 工程实践：在微服务项目中通常需要同时使用两者； 性能影响：分离后生成的代码更专注，编译产物更精简。 正确使用这两个生成器是构建高效 gRPC 服务的基石，开发者应根据实际需求选择生成策略。\n实现 grpc 服务端 $ vim main.go package main import ( \"context\" \"fmt\" \"log\" \"net\" \"google.golang.org/grpc\" \"test/helloworld\" ) type testHello struct { helloworld.UnimplementedHelloServiceServer Name string } // SayHello func (t *testHello) SayHello(ctx context.Context, req *helloworld.HelloRequest) (*helloworld.HelloResponse, error) { result := \u0026helloworld.HelloResponse{Reply: \"hello world!\"} // TODO; ... return result, nil } func main() { fmt.Println(\"start test grpc server\") lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"localhost:%d\", 10081)) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } var opts []grpc.ServerOption grpcServer := grpc.NewServer(opts...) helloworld.RegisterHelloServiceServer(grpcServer, \u0026testHello{Name: \"test\"}) grpcServer.Serve(lis) } $ go mod init test $ go mod tidy $ go run main.go 客户端接入 Go 客户端 依赖 go 语言存根，生成方式见通过 protoc 工具编译。\npackage main import ( \"context\" \"fmt\" \"log\" \"google.golang.org/grpc\" \"google.golang.org/grpc/credentials/insecure\" \"test/helloworld\" ) func main() { var opts []grpc.DialOption opts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials())) conn, err := grpc.NewClient(\"127.0.0.1:10081\", opts...) if err != nil { log.Fatalf(\"failed to create client: %v\", err) } defer conn.Close() client := helloworld.NewHelloServiceClient(conn) req := \u0026helloworld.HelloRequest{} ctx := context.TODO() resp, err := client.SayHello(ctx, req) if err != nil { log.Fatalf(\"failed to rpc server: %v\", err) } fmt.Println(\"resp:\", resp) } $ go run client.go resp: reply:\"hello world!\" $ Python 客户端 依赖 python 语言存根，生成方式如：\n安装依赖 $ python3 -m pip3 install grpcio $ python3 -m pip3 install grpcio-tools 生成 python 语言存根 python3 \\ -m grpc_tools.protoc \\ -I ./ \\ --python_out=. \\ --grpc_python_out=. \\ helloworld/helloworld.proto 实现客户端调用通讯 import grpc from helloworld import helloworld_pb2 from helloworld import helloworld_pb2_grpc grpc_endpoint = \"127.0.0.1:10081\" def main(): channel = grpc.insecure_channel(grpc_endpoint) stub = helloworld_pb2_grpc.HelloServiceStub(channel) req = helloworld_pb2.HelloRequest() resp = stub.SayHello(req) print(resp) if __name__ == \"__main__\": main() $ python3 client.py reply: \"hello world!\" $ ","categories":"","description":"","excerpt":"简要概述 对在 go 语言下使用 grpc 的快速入门。\n环境准备 编译器安装 Go 语言 环境安装； Protocol buffer 编译 …","ref":"/docs/concepts/grpc/language-go/","tags":"","title":"示例：go"},{"body":" 用于规范定义 rpc、http restful 接口设计，以便准守相同规则的人可以更轻松地协同工作\n","categories":"","description":"","excerpt":" 用于规范定义 rpc、http restful 接口设计，以便准守相同规则的人可以更轻松地协同工作\n","ref":"/docs/spec-api/","tags":"","title":"接口规范"},{"body":"简要概述 支持 memory、redis 实现数据临时缓存，以降低查询后端数据库压力。\n配置示例 最小化配置 # 缓存服务配置 cachebox: enable: true driver: memory memory: max_entry: 60 导出默认值 # 缓存服务配置 cachebox: enable: true driver: redis # memory, redis memory: max_entry: 1024 redis: endpoints: - 127.0.0.1:6380 - 127.0.0.1:6381 - 127.0.0.1:6382 username: \"\" password: \"\" db_number: 1 sentinel: master_name: \"\" username: \"\" password: \"\" tls_client_config: ca_file: \"\" cert_file: \"\" key_file: \"\" insecure_skip_verify: true 函数定义 公共接口 // LRUCachebox 缓存实现 LRU 效果 type LRUCachebox interface { // Remove 重内存缓存移除值 Remove(ctx context.Context, key string) bool // SetValue 向内存缓存添加值 SetValue(ctx context.Context, key string, value any) bool // GetStructValue 从内存缓存获取值，并填充用户给定的类型 GetStructValue(ctx context.Context, key string, ptx any) bool } 获取实例 // GetLRUCachebox 用于获取 LRU 缓存 func (c *LocalConfig) GetLRUCachebox() (LRUCachebox, error) { ...... } // GetCacheboxRedisClient 用于获取缓存服务中初始化的 redis 连接 func (c *LocalConfig) GetCacheboxRedisClient() (redis.UniversalClient, error) { ...... } // HasCacheboxEnabled 用于判断是否启用缓存 func (c *LocalConfig) HasCacheboxEnabled() bool { ...... } 应用场景 使用内存缓存 app.yaml 配置 # 缓存服务配置 cachebox: enable: true driver: memory # memory, redis memory: max_entry: 60 获取实例 // 判断配置中是否开启缓存 if m.baseCfg.HasCacheboxEnabled() { lruCache, err := m.baseCfg.GetLRUCachebox() if err == nil \u0026\u0026 lruCache != nil { if lruCache.SetValue(ctx, cacheKey, u) { m.logger.Debugf(\"set cache success success\") } } } 使用单实例 redis 缓存 app.yaml 配置 # 缓存服务配置 cachebox: enable: true driver: redis redis: endpoints: - 127.0.0.1:6379 db_number: 0 获取实例 同上。\n使用 redis cluster 缓存 app.yaml 配置 # 缓存服务配置 cachebox: enable: true driver: redis redis: endpoints: - 127.0.0.1:6380 - 127.0.0.1:6381 - 127.0.0.1:6382 username: \"\" password: \"\" 获取实例 同上。\n使用 redis sentinel 缓存 app.yaml 配置 # 缓存服务配置 cachebox: enable: true driver: redis redis: endpoints: - 127.0.0.1:6380 - 127.0.0.1:6381 - 127.0.0.1:6382 sentinel: master_name: \"test\" username: \"\" password: \"\" 获取实例 同上。\n","categories":"","description":"","excerpt":"简要概述 支持 memory、redis 实现数据临时缓存，以降低查询后端数据库压力。\n配置示例 最小化配置 # …","ref":"/docs/spec-cfg/cachebox/","tags":"","title":"缓存服务"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/devops/","tags":"","title":"运维管理"},{"body":"简要概述 用于链路跟踪、指标数据采集上报。\n配置示例 最小化配置 # 分布式链路追踪 #observables: # enable: true 可不做任何配置，默认开启可观测性指标服务，既直接对外暴露 “/metrics” 地址。\n导出所有项 # 可观测性配置 observables: # 全局是否启动可观测性，默认启用 enable: true # 遥测数据（指标、链路）的个性行为配置 telemetry: # 指标数据 metrics: # 为所有自定义指标添加前缀 namespace: default # 性能数据上报频率，单位：秒 push_interval: 60 # 配置启用的 exporters 插件 exporter_enable: otlp: false otlphttp: false logging: true prometheus: true # 链路数据 traces: # 给定一个 0 至 1 之间的分数决定采样频率 sample_ratio: 1 # 在网关上记录 http 请求与响应体内容，仅当为 json 结构体有效 log_fields: http_request: true http_response: true # 配置启用的 exporters 插件 exporter_enable: otlp: true otlphttp: true logging: true prometheus: false # 过滤 http 或 grpc 请求的链路数据上报 filters: - url_path: \"/api/demo\" method: POST - method: Demo # 遥测数据（指标、链路）的上报输出配置 exporters: # 通过 grpc 上报数据 otlp: endpoint: \"http://127.0.0.1:4317\" headers: Authentication: token # 通过 http 上报数据，避免与 oltp 配置多个，否则链路会重复 #otlphttp: # endpoint: \"http://127.0.0.1:4318\" # traces_url_path: \"\" # metrics_url_path: \"\" # headers: # Authentication: token # 对外暴露 prometheus 风格的 http url 地址 prometheus: metrics_url_path: \"/metrics\" # 指标与链路分布写入本地文件路径 logging: pretty_print: true traces_file_path: \"/tmp/traces.log\" metrics_file_path: \"/tmp/metrics.log\" 参数说明 ObservablesConfig 名称 类型 说明 enable bool 全局是否启动可观测性，默认启用 telemetry TelemetryConfig 遥测数据（指标、链路）的个性行为配置 exporters ExporterConfig 遥测数据（指标、链路）的上报输出配置 TelemetryConfig 名称 类型 说明 metrics TelemetryMetric 指标数据配置 traces TelemetryTrace 链路跟踪配置 TelemetryMetric 名称 类型 说明 namespace string 命名空间，为所有暴露的指标添加前缀 push_interval int 性能数据上报频率，默认1分钟，单位：秒 exporter_enable ExporterEnable 是否启用 Exporters 配置下的 otel otelhttp logging prometheus ExporterEnable 名称 类型 说明 otlp bool 指标或链路是否启用通道 observables.exporters.otlp 上报数据 otlphttp bool 指标或链路是否启用通道 observables.exporters.otlphttp 上报数据 prometheus bool 指标是否启用通道 observables.exporters.prometheus 输出数据 logging bool 指标或链路是否启用通道 observables.exporters.logging 输出数据 TelemetryTrace 名称 类型 说明 sample_ratio float64 给定一个 0 至 1 之间的分数决定采样频率 log_fields LogFields 记录特殊字段，默认不开启 filters Filters 过滤器，用于过滤不需要追踪的请求 exporter_enable ExporterEnable 是否启用 Exporters 配置下的 otel otelhttp logging prometheus LogFields 名称 类型 说明 http_request bool 是否记录请求体 http_response bool 是否记录响应体 Filters 名称 类型 说明 method string http method 或者 grpc method url_path string http url ExporterConfig 名称 类型 说明 otlp OTLPGRPCConfig 使用 otlp grpc 协议上报数据 otlphttp OTLPHTTPConfig 使用 otlp http 协议上报数据 prometheus Prometheus 使用 prometheus http 服务输出数据 logging Logging 使用本地文件输出数据 OTLPGRPCConfig 名称 类型 说明 endpoint string 服务端地址 headers map[string]string 请求头，有些认证需在这里添加，如：Authentication OTLPHTTPConfig 名称 类型 说明 endpoint string 服务端地址 headers map[string]string 有些认证需在这里添加，如：Authentication traces_url_path string 链路上报接口地址，默认为：/v1/traces metrics_url_path string 指标上报接口节点，默认为：/v1/metrics Prometheus 名称 类型 说明 metrics_url_path string 对外暴露应用指标的 http url 地址，默认为：/metrics Logging 名称 类型 说明 pretty_print bool 是否格式化 json 输出 metrics_file_path string 指标输出文件，为空则不启用，配置 “stdout” 则输出终端 traces_file_path string 链路输出文件，为空则不启用，配置 “stdout” 则输出终端 使用场景 对接阿里云服务 服务端接收数据 购买 可观测链路 OpenTelemetry 版 服务。\n客户端上报数据 使用 gRPC 上报\n# 可观测性配置 observables: exporters: otlp: endpoint: http://tracing-analysis-dc-hz.aliyuncs.com:8090 headers: Authentication: \"配置云平台获取的 token\" 使用 HTTP 上报\n# 可观测性配置 observables: enable: true exporters: otlphttp: endpoint: http://tracing-analysis-dc-hz.aliyuncs.com traces_url_path: \"/xyz@xyz/api/otlp/traces\" metrics_url_path: \"/xyz@xyz/api/otlp/metrics\" 监控与告警展示 登录后台 https://tracing.console.aliyun.com 查看。\n对接腾讯云服务 服务端接收数据 购买 应用性能监控 服务。\n客户端上报数据 通过设置环境变量 OTEL_RESOURCE_ATTRIBUTES=token=xxxxxxxxx 设置授权，Token 在云服务后台上可找到。\n# 可观测性配置 observables: exporters: otlp: endpoint: http://ap-guangzhou.apm.tencentcs.com:4317 监控与告警展示 登录后台 https://console.cloud.tencent.com/apm/monitor/system 查看。\n对接 honeycomb 服务 服务端接收数据 购买 Honeycomb 服务。\n客户端上报数据 # 可观测性配置 observables: exporters: otlp: endpoint: https://api.honeycomb.io:443 headers: \"x-honeycomb-team\": \"配置云平台获取的 token\" 监控与告警展示 登录后台 https://ui.honeycomb.io/ 查看。\n对接私有 jaeger 服务 服务端接收数据 在本地启动 jaeger all-in-one 容器\ndocker run --rm --name jaeger \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ jaegertracing/all-in-one:1.50 这里端口 4317 为 grpc 协议，4318 为 http 协议，16686 为 jaeger ui 服务，all-in-one 仅用于开发环境，生产环境需各组件单独部署以便实现高可用。\n客户端上报数据 配置服务使用 otlp 使用上报链路数据\n# 可观测性配置 observables: exporters: otlp: endpoint: http://127.0.0.1:4317 监控与告警展示 访问 http://localhost:16686 查看。\n过滤特定请求的链路上报 # 可观测性配置 observables: exporters: ...... telemetry: traces: filters: - url_path: \"/api/test\" method: POST - method: Test 这里将会过滤本服务请求为 http method 为 POST 且地址为 “/api/test” 或 grpc 方法为 “Test” 的链路数据。\n更改对外暴露的 http prometheus 性能数据地址 # 可观测性配置 observables: exporters: prometheus: metrics_url_path: /v2/metrics 这个时候需通过接口 “/v2/metrics” 来获取应用的性能数据。\n自定义 http 接口如何实现跟踪 默认仅针对 grpc-gateway 至 grpc 转发才会捕获链路数据上报。\n如果用户在 handler/private.go 中的 privateHTTPHandle 方法添加了自定义 http 接口，如：\nfunc (m *Microservice) privateHTTPHandle(mux *http.ServeMux) error { testHandler := func(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \"test\") } // 访问 /favicon.ico 不会产生链路数据 mux.HandleFunc(\"/favicon.ico\", func(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \"\") }) // 访问 /test 会产生链路数据 mux.Handle(\"/test\", m.baseCfg.HTTPHandlerFunc(testHandler)) return nil } 这里定义了两个接口 /favicon.ico（不会产生链路数据） 与 /test（会产生链路数据），如需捕获数据，可通过内置函数 m.baseCfg.HTTPHandlerFunc 或 m.baseCfg.HTTPHandler 实现。\n","categories":"","description":"","excerpt":"简要概述 用于链路跟踪、指标数据采集上报。\n配置示例 最小化配置 # 分布式链路追踪 #observables: # enable: …","ref":"/docs/spec-cfg/observables/","tags":"","title":"可观测性"},{"body":"简要概述 基于 minio-go 类库，对接兼容亚马逊 S3 标准的对象存储，通过封装 ObjstoreBucket 接口，以便在应用层简化使用。\n已测试以下服务：\n腾讯云 COS 阿里云 OSS Cloudflare R2 ObjstoreBucket // ObjstoreBucket 抽象化包装，以简化使用，读写操作权限 type ObjstoreBucket interface { io.Closer ObjstoreBucketReader // Name 获取默认的 bucket 名称 Name() string // Upload 用于上传对象到默认的 bucket 里 Upload(ctx context.Context, objectKey string, r io.Reader) (ObjstoreAttributes, error) // Delete 用于删除对象在默认的 bucket 里 Delete(ctx context.Context, objectKey string) error // CopyTo 用于拷贝对象在默认 bucket 里 CopyTo(ctx context.Context, srcObjectKey, dstObjectKey string) (ObjstoreAttributes, error) } // ObjstoreBucketReader 抽象化包装，以简化使用，只读操作权限 type ObjstoreBucketReader interface { // Get 用于获取默认 bucket 的对象内容 Get(ctx context.Context, objectKey string) (io.ReadCloser, ObjstoreAttributes, error) // Iter 用于遍历默认 bucket 里的对象文件 Iter(ctx context.Context, dir string, f func(string) error) error // GetRange 用于获取默认 bucket 中对象指定位置的内容 GetRange(ctx context.Context, objectKey string, start, end int64) (io.ReadCloser, ObjstoreAttributes, error) // Exists 用于判断默认 bucket 是否存在该对象 Exists(ctx context.Context, objectKey string) (bool, error) // Attributes 用于获取默认 bucket 中对象的额外属性 Attributes(ctx context.Context, objectKey string) (ObjstoreAttributes, error) // IsObjNotFoundErr 错误是否为查询的对象不存在 IsObjNotFoundErr(err error) bool } ObjstoreAttributes // ObjstoreAttributes 对象属性信息，如：last_modified、etag 等 type ObjstoreAttributes struct { // ETag 对象文件内容的 md5 值 ETag string `json:\"etag\"` // LastModified 对象文件最近被修改时间 LastModified time.Time `json:\"last_modified\"` // Size 对象文件大小，单位 bytes Size int64 `json:\"size\"` // UserMetadata 用户额外定义该对象的元数据，以 \"x-amz-meta-*\" 请求头返回 UserMetadata map[string]string `json:\"user_metadata\"` // UserTags 用户定义对象文件关联的标签 UserTags map[string]string `json:\"user_tags\"` // VersionID 用于说明本次文件版本号 VersionID string `json:\"version_id\"` } 功能点支持情况 方法名 功能点 腾讯云 阿里云 Cloudflare Upload 上传文件 是 是 是 Delete 删除对下 是 是 是 Get 获取文件 是 是 是 Iter 遍历文件 是 是 是 GetRange 获取文件 是 是 是 Exists 文件是否存在 是 是 是 SSE-KMS 使用 KMS 加密 是 是 是 SSE-C 使用自定义密钥 是 否 否 SSE-S3 使用提供商密钥 是 是 是 put_user_metadata 用户自定义元数据 是 是 是 put_user_tags 用户自定义标签 是 否 否 配置示例 最小化配置 objstore: enable: true type: s3 config: bucket: \"uptime-syncds-1251023941\" endpoint: \"cos.ap-guangzhou.myqcloud.com\" access_key: \"\" secret_key: \"\" 导出默认值 objstore: enable: true type: s3 config: bucket: \"\" endpoint: \"\" region: \"\" access_key: \"\" insecure: true secret_key: \"\" put_user_metadata: {} put_user_tags: {} http_config: idle_conn_timeout: 1m signature_version: v4 list_objects_version: v2 bucket_lookup_type: auto part_size: 67108864 sse_config: type: \"\" kms_key_id: \"\" kms_encryption_context: {} encryption_key: \"\" 配置说明 Config 名称 类型 说明 bucket string 默认 bucket 名称 endpoint string 连接对象存储服务端的地址 region string 对象存储的区域 access_key string 对象存储的授权ID，支持环境变量 insecure bool 使用 http 或 https 连接对象存储服务端 secret_key string 对象存储的授权密钥，支持环境变量 session_token string 对象存储的授权密钥，支持环境变量 put_user_metadata map[string]string 上传文件时用户添加的元数据，在 http 获取对象时，以: x-amz-meta-{label}={value} 请求头返回 put_user_tags map[string]string 上传文件时用户添加的标签 http_config HTTPConfig 用于控制客户端通过 http 协议连接服务端的一些能力 signature_version string 客户端请求 s3 服务端使用的签名算法版本，取值：v2、v4，默认：v4 list_objects_version string 查询对象文件列表使用的接口版本，取值：v1、v2，默认：v2 bucket_lookup_type string 用于表示 bucket 的 URL 风格，可取值：auto、virtual-hosted、path part_size uint64 用于大文件分块上传，单位字节，默认为：1024 * 1024 * 64，既64MB，最大分块不要超过 10000 个文件 sse_config SSEConfig 用于配置对象存储服务端加密 其中 access_key、secret_key 也可使用以下环境变量代替：\naccess_key secret_key session_token AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN AWS_ACCESS_KEY AWS_SECRET_KEY - MINIO_ACCESS_KEY MINIO_SECRET_KEY - MINIO_ROOT_USER MINIO_ROOT_PASSWORD - 其中 access_key、secret_key 也可以使用 aws 的配置文件：\n文件地址优先读取环境变量 “AWS_SHARED_CREDENTIALS_FILE” 如果为空，则使用以下默认地址：\n$HOME/.aws/credentials 示例格式：\n[default] aws_access_key_id={aws_access_key_id} aws_secret_access_key={aws_secret_access_key} HTTPConfig 名称 类型 说明 tls_client_config TLSConfig 允许你自定义 TLS 配置，以满足特定的需求，例如指定根证书、跳过证书验证、设置密码套件等 tls_handshake_timeout time.Duration 可以控制在建立 TLS 握手过程中等待的最大时间，客户端和服务器之间进行密钥交换和协商加密参数等操作，如果在指定的超时时间内未完成握手，客户端可以终止连接或采取其他处理方式 disable_keep_alives bool HTTP 的 keep-alive 是一种机制，允许客户端在单个 TCP 连接上发送多个 HTTP 请求，而无需为每个请求都建立和关闭连接，是否禁用 HTTP 的 keep-alive 功能，这样每个 HTTP 请求都会使用一个新的连接，意味着每次请求都需要建立和关闭连接 disable_compression bool 如果开启则请求中不会包含 “Accept-Encoding: gzip” 的请求头，即禁止了请求压缩，这意味着即使服务端返回的响应使用了gzip压缩，Transport也不会自动解压缩响应体 max_idle_conns int 可以控制在空闲连接池中保持的最大连接数，超过这个数量的空闲连接将被关闭，通过使用 keep-alive 机制，客户端可以在多次请求之间重用已经建立的连接，以减少每次请求的连接建立和断开的开销 max_idle_conns_per_host int 可以针对每个主机控制保持的最大空闲连接数，这可以使每个主机具有独立的连接池，而不是使用全局的连接池，每个主机可以独立地管理和复用空闲连接，以优化连接的使用和性能 max_conns_per_host int 用于可选地限制每个主机的总连接数，包括处于拨号、活动和空闲状态的连接 idle_conn_timeout time.Duration 空闲连接的超时时间，指定空闲连接在关闭之前保持的最长时间 response_header_timeout time.Duration 客户端在发送请求后等待服务器响应头的时间，如果在指定的超时时间内未收到响应头，客户端可以终止连接或采取其他处理方式 expect_continue_timeout time.Duration 用于在完全发送请求头后，等待服务器首次响应头的时间 max_response_header_bytes int 可以控制接收和处理服务器响应头的大小，响应头中包含了诸如状态码、响应头字段等信息，如果服务器的响应头超过了指定的最大字节数，那么将会触发一个错误，导致请求失败 write_buffer_size int 用于控制写缓冲区大小，它是用于临时存储要发送到传输层的数据的内存区域，设置为 0，则会使用默认值（目前为4KB） read_buffer_size int 用于控制读缓冲区大小，它是用于临时存储从传输层读取的数据的内存区域，设置为 0，则会使用默认值（目前为4KB） force_attempt_http2 bool 在配置了 Dial、DialTLS、DialContext 函数或 TLSClientConfig 时，会禁用 HTTP/2，这时可以配置开启，也会尝试使用 HTTP/2 协议进行升级，不过仍然需要确保服务器支持 HTTP/2 协议才能成功升级 TLSConfig 名称 类型 说明 server_name string 进行 TLS 握手时，客户端会检查服务器返回的证书中的主机名与客户端期望的主机名是否匹配 insecure_skip_verify bool 默认情况下，客户端会验证服务器的证书链和主机名，以确保建立安全的 TLS 连接，避免被中间人攻击 min_version string 最低支持的 tls 版本，取值范围：TLSv1 TLSv1.1 TLSv1.2 TLSv1.3 max_version string 最高支持的 tls 版本，取值范围：TLSv1 TLSv1.1 TLSv1.2 TLSv1.3 ca_file string 用于定义客户端在验证服务器证书时使用的根证书，一般在自签证书时使用 cert_file string 客户端证书公钥 key_file string 客户端证书私钥 SSEConfig 名称 类型 说明 type string 用于对象加密，可取值：SSE-KMS、SSE-C、SSE-S3 kms_key_id string x kms_encryption_context map[string]string x encryption_key string 配合 SSE-C 使用，指向存放 32 字节长度的密钥文件地址 是否支持三种加密方式，不同的云提供商可能存在差异，已知如下：\n腾讯云COS支持：SSE-KMS、SSE-C、SSE-S3 阿里云OSS支持：SSE-KMS、SSE-S3 使用KMS托管密钥：SSE-KMS 一般需先在云提供商购买密钥管理服务，才可以使用。\n客户自定义密钥：SSE-C 会把密钥通过 base64 加密，并通过 http 请求头传递，所以这种情况下建议使用 HTTPS 进行传输，参考文档。\n名称 示例 说明 X-Amz-Server-Side-Encryption-Customer-Key-Md5 wlnU57TLDGlZNVzlkvopog== 服务端使用此标头进行消息完整性检查以确保加密密钥传输无误 X-Amz-Server-Side-Encryption-Customer-Algorithm AES256 指定加密算法，这里一定是 AES256 X-Amz-Server-Side-Encryption-Customer-Key QUZtQXdJQlFpSWFyZEk0NURoNXlxM3NoZzVQUzVvN1I= 加密密钥的 base64 编码 应用场景 使用腾讯云低频存储 # 对象存储配置 objstore: enable: true type: s3 config: bucket: \"uptime-syncds-1251023941\" endpoint: \"cos.ap-guangzhou.myqcloud.com\" region: \"ap-guangzhou\" access_key: \"\" secret_key: \"\" put_user_metadata: x-amz-storage-class: \"STANDARD_IA\" 通过添加用户自定义元数据 “x-amz-storage-class” 为 “STANDARD_IA” 实现，存储类型参考文档。\n使用托管的密钥加密 # 对象存储配置 objstore: enable: true type: s3 config: bucket: \"uptime-syncds-1251023941\" endpoint: \"cos.ap-guangzhou.myqcloud.com\" region: \"ap-guangzhou\" access_key: \"\" secret_key: \"\" sse_config: type: \"SSE-S3\" 可以直接使用各云提供商托管的密钥进行服务端加密。使用上通过设置 “sse_config” 类型为 “SSE-S3”，当上传的所有对象均以各云提供商托管的密钥进行加密数据。\n使用自定义加密密钥 对象存储配置部分 # 对象存储配置 objstore: enable: true type: s3 config: bucket: \"uptime-syncds-1251023941\" endpoint: \"cos.ap-guangzhou.myqcloud.com\" region: \"ap-guangzhou\" access_key: \"\" secret_key: \"\" sse_config: type: \"SSE-C\" encryption_key: \"/opt/config/secret.key\" 使用 “SSE-C” 加密类型，配置密钥路径为 “/opt/config/secret.key”，内容必须为长度 32 字节，如：“AFmAwIBQiIardI45Dh5yq3shg5PS5o7RYou”。\n可通过 cat /opt/config/secret.key | wc -c 结果必须等于 32 如果为 33 则注意末尾隐藏的换行符号 \\n。\n生成 secret.key 内容 以下以字母大小写、数字组合生成 32 字节长度的随机字符串：\npackage main import ( \"crypto/rand\" \"fmt\" \"log\" \"math/big\" ) func generateSSECKey() (string, error) { const charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" charsetLen := big.NewInt(int64(len(charset))) key := make([]byte, 32) for i := range key { randomIndex, err := rand.Int(rand.Reader, charsetLen) if err != nil { return \"\", err } key[i] = charset[randomIndex.Int64()] } return string(key), nil } func main() { ssecKey, err := generateSSECKey() if err != nil { log.Fatal(err) } fmt.Print(ssecKey) } 使用 go 编译，并把结果写入文件 /opt/config/secret.key 中。\ngo run a.go \u003e /opt/config/secret.key ","categories":"","description":"","excerpt":"简要概述 基于 minio-go 类库，对接兼容亚马逊 S3 标准的对象存储，通过封装 ObjstoreBucket 接口，以便在应用层简化 …","ref":"/docs/spec-cfg/objstore/","tags":"","title":"对象存储"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/changelog/","tags":"","title":"更新日志"},{"body":"简要概述 基于 argo workflow 实现对各个原子接口编排完成较复杂的任务流程。\n引入改模块后对编译后的二进制增加大约 4M 大小。\n配置示例 最小化配置 # 流程编排配置 automations: enable: true 导出默认值 # 流程编排配置 automations: enable: false kubernetes: config_path: \"\" rest_config: host: \"\" bearer_token: \"\" bearer_token_file: \"\" tls_client_config: insecure: false 配置说明 KubernetesConfig 名称 类型 说明 config_path string 连接 k8s 的 kubeconfig 配置文件地址 rest_config RestConfig 连接 k8s 的 rest config 配置参数，优先级低于 config_path RestConfig 名称 类型 说明 host string kube-apiserver 地址，如 1.1.1.1:6443 bearer_token string 访问 apiserver 的 token bearer_token_file string 访问 apiserver 的 token 文件，优先级低于 bearer_token tls_client_config TLSClientConfig 连接 apiserver tls 配置 TLSClientConfig 名称 类型 说明 insecure bool 是否忽略 ca 证书验证 应用场景 在集群内连接 apiserver 配置 app.yaml 文件 # 流程编排配置 automations: enable: true 如果未主动配置 k8s 连接串，则使用 “InClusterConfig” 模式连接 kube-apiserver，依赖以下变量与文件：\nKUBERNETES_SERVICE_HOST KUBERNETES_SERVICE_PORT /var/run/secrets/kubernetes.io/serviceaccount/token /var/run/secrets/kubernetes.io/serviceaccount/ca.crt 确认 sa 挂载了 token 假设运行 pod 的 sa 账号是 “grpc-kit”。\n开启 “automountServiceAccountToken” 参数以自动挂载 token（默认开启状态）：\napiVersion: v1 kind: ServiceAccount metadata: name: grpc-kit automountServiceAccountToken: true 或者在 Pod 中开启（默认开启状态）：\napiVersion: v1 kind: Pod metadata: name: example-pod spec: automountServiceAccountToken: true 确认 sa 用于创建 workflow 权限 假设应用运行在命名空间 “biz-dev-uptime” 下使用 “grpc-kit” 账户：\n--- apiVersion: v1 kind: ServiceAccount metadata: name: grpc-kit namespace: biz-dev-uptime --- apiVersion: v1 kind: Secret type: kubernetes.io/service-account-token metadata: name: grpc-kit namespace: biz-dev-uptime annotations: kubernetes.io/service-account.name: grpc-kit --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: executor rules: - apiGroups: - argoproj.io resources: - workflowtaskresults - workflowtemplates verbs: - create - patch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: executor roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: executor subjects: - kind: ServiceAccount name: grpc-kit namespace: biz-dev-uptime ","categories":"","description":"","excerpt":"简要概述 基于 argo workflow 实现对各个原子接口编排完成较复杂的任务流程。\n引入改模块后对编译后的二进制增加大约 4M 大小。 …","ref":"/docs/spec-cfg/automations/","tags":"","title":"流程编排"},{"body":"简要概述 支持托管静态文件，例如编写 HTML、CSS、JAVASCRIPT 部署到指定目录下，既可在前端浏览器打开展示，同时也支持这些静态文件在编译时嵌入二进制中。\n一般常见可通过以下框架生成：\nHugo Next.js 在使用托管服务时，需按照以下规范使用：\n前端类型 默认 URL 地址 前端源代码路径 前端编译后路径 admin /admin/ ./web/admin/ ./public/admin/ openapi /openapi-spec/ ./api/${}/microservice.openapiv2.yaml ./public/openapi/ webroot / ./web/webroot/ ./public/webroot/ 配置示例 最小化配置 # 前端托管配置 #frontend: # enable: true 可不做任何配置，默认开启：openapi 接口文档。\n导出默认值 # 前端托管配置 frontend: enable: true interface: admin: enabled: false tracing: false embedded: true handle_url: /admin openapi: enabled: true tracing: false embedded: true handle_url: /openapi-spec webroot: enabled: false tracing: false embedded: true handle_url: / 配置说明 FrontendInterface 名称 类型 说明 admin WebInterfaceConfig 面向管理员后台 openapi WebInterfaceConfig 基于 protoc 服务定义转换为 http 接口文档 webroot WebInterfaceConfig 面向普通用户所使用的前端页面 WebInterfaceConfig 名称 类型 说明 enabled bool 是否启用该前端托管 tracing bool 是否启用该托管的链路跟踪 embedded bool 是否把该前端静态文件在编译时嵌入二进制文件中 handle_url string 注册到微服务上 http url 服务的地址 应用场景 禁止目录列出 应用配置：\n# 前端托管配置 frontend: interface: admin: enabled: true 静态目录：\nhello1.txt dir1/dir2/hello2.txt 使用以上配置，开启 “./public/admin/” 静态文件托管，此时在浏览器上访问将会以目录列表输出，这在某些情况下存在安全风险，可通过以下两种方式禁止目录列出。\n方式一：为各目录下添加 “index.html” 文件\n在浏览器访问时自动会把 “index.html” 内容输出，但此种方式仅影响当前文件夹。\n方式二：在根目录下添加 “404.html” 文件\n当请求的 “*.html” 或者 请求无后缀 文件时，如果不存在文件则会重定向到根的 “404.html” 内容。\n自定义 404 页面 如上，在根目录更改 “404.html” 文件即可。\n取消内嵌静态文件 应用配置：\n# 前端托管配置 frontend: interface: admin: enabled: true embedded: false 使用以上配置，开启 “./public/admin/” 静态文件托管，此时目录下内容更改可实时生效并影响到用户前端访问。\n开启链路跟踪 # 前端托管配置 frontend: interface: admin: enabled: true tracing: true 使用以上配置，开启 “./public/admin/” 静态文件托管，用户访问 “/admin” 后台时，将会把相关链路数据上报至已配置的可观测性服务。\n使用 next.js 生成模版 npx create-next-app@latest \\ --typescript \\ --tailwind \\ --eslint \\ --app \\ --use-npm \\ --import-alias \"@/*\" webroot 更改配置 next.config.js\n/** @type {import('next').NextConfig} */ const nextConfig = { output: 'export', distDir: '../../public/webroot', trailingSlash: true, } module.exports = nextConfig ","categories":"","description":"","excerpt":"简要概述 支持托管静态文件，例如编写 HTML、CSS、JAVASCRIPT 部署到指定目录下，既可在前端浏览器打开展示，同时也支持这些静态 …","ref":"/docs/spec-cfg/frontend/","tags":"","title":"前端托管"},{"body":"简要概述 对于通过 grpc-kit-cli 生成的每个微服务模版，如果它们存在需要个性化配置与数据结构，那么可以在这里定义。\n配置示例 independent: name: grpc-kit 数据结构 在 github.com/grpc-kit/pkg/cfg 中内置的数据结构，这个由框架管理，用户无法自定义：\ntype LocalConfig struct { ...... Independent interface{} `json:\",omitempty\"` // 应用私有配置 ...... } 在生成各服务模版的结构，这个由用户自定义：\npackage modeler // IndependentCfg 个性配置 type IndependentCfg struct { Name string `mapstructure:\"name\"` } // Init 用于初始化实例 func (i *IndependentCfg) Init() error { // 业务代码 return nil } 应用场景 一个自定义服务 生成以下 app.yaml 配置项：\n# 应用私有配置 independent: # 消息数据写入kafka的topic message: cmdb: # 资产类信息 topic: uptime-alertmanager metric: # 性能指标类 topic: uptime # 主机注册的相关配置 registry: default: host_ttl: 60 heartbeat: 10 在对应的 modeler/independent_cfg.go 中数据结构为：\n// IndependentCfg 个性配置 type IndependentCfg struct { Message MessageConfig `mapstructure:\"message\"` Registry RegistryConfig `mapstructure:\"registry\"` } // MessageConfig 用于kafka消息的配置 type MessageConfig struct { CMDB struct { Topic string `mapstructure:\"topic\"` } `mapstructure:\"cmdb\"` Metric struct { Topic string `mapstructure:\"topic\"` Drop bool `mapstructure:\"drop\"` } `mapstructure:\"metric\"` } // RegistryConfig xx type RegistryConfig struct { Default ConfigContent `mapstructure:\"default\"` } // ConfigContent 一个具体的配置项 type ConfigContent struct { // Address 隧道的地址 Address []string `mapstructure:\"address\"` // 主机注册存活的时间 HostTTL int `mapstructure:\"host_ttl\"` // 维持主机心跳时间，必须小于 host_ttl Heartbeat int `mapstructure:\"heartbeat\"` } ","categories":"","description":"","excerpt":"简要概述 对于通过 grpc-kit-cli 生成的每个微服务模版，如果它们存在需要个性化配置与数据结构，那么可以在这里定义。 …","ref":"/docs/spec-cfg/independent/","tags":"","title":"应用私有"},{"body":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前为Deprecated状态，此版本被移除 Fixed 功能的修复 Security 有关安全问题的修复 [Unreleased] [0.3.2] - 2023-05-28 Added 更改 gitlab runner 为有向无环图 (DAG) 流水线 每个 job 均使用独立的容器来运行，避免无意义拆分多个 job； 在根目录默认生成 Dockerfile 文件； 确定默认镜像相关使用的变量名； 为方便 nginx 配置路由转发，更改 swagger 使用相对地址 由原先 “/openapi-spec/microservice.swagger.json” 更改为 “./microservice.swagger.json”\n\u003cbody\u003e \u003credoc spec-url='./microservice.swagger.json'\u003e\u003c/redoc\u003e \u003cscript src=\"./redoc.standalone.js\"\u003e \u003c/script\u003e \u003c/body\u003e 在 nginx 中 location 配置\nlocation /opsaid/test1/v1/openapi-spec/ { proxy_pass http://opsaid-test1:10080/openapi-spec/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } 实现对接口文档的转发\n修复 gitlab 的 check-protoc 阶段检测文件错误 protoc-gen-go-grpc gitlab runner 更改为 有向无环图 (DAG) 流水线 每个 job 均使用独立的 容器 来运行，适合用来运行独立的任务，加快速度，避免无意义拆分多个 job； 让 Dockerfile 默认生成； 确定默认镜像使用的变量名； ```shell CI_REGISTRY CI_REGISTRY_IMAGE CI_REGISTRY_USER CI_REGISTRY_PASSWORD ``` 进入：https://{gitlab}/-/settings/ci_cd，设置好变量。 新增 jenkins 流水线模版配置 .jenkins/workflows/Jenkinsfile 依赖 k8s 环境，需提前配置好，参考 Jenkins Pipeline。\n统一规范 CICD 变量名 新增 scripts/variable.sh 用于动态变量生成； 区别 scripts/env 用于全局静态变量； 支持静态配置编译运行时的变量，文件路径 scripts/env-${DEPLOY_ENV}-${BUILD_ENV}； 更改本微服务的 proto 为相对路径 github.com/opsaid/test1/api/opsaid/test1/v1/microservice.proto 更改为 api/opsaid/test1/v1/microservice.proto 为解决服务在容器内构建时，如果为绝对路径，则代码目录必须存放至 $GOPATH/src/$REPOSITORY 路径下，否则无法运行。\nprotoc \\ -I ./ \\ -I /usr/local/include/ \\ -I \"${GOPATH}\"/src \\ -I \"${GOPATH}\"/src/github.com/grpc-ecosystem/grpc-gateway/ \\ -I \"${GOPATH}\"/src/github.com/googleapis/googleapis/ \\ --go_opt paths=source_relative \\ --go_out ./ \\ --go-grpc_opt paths=source_relative \\ --go-grpc_opt require_unimplemented_servers=false \\ --go-grpc_out ./ \\ ./api/opsaid/test5/${API_VERSION}/*.proto 添加 paths=source_relative 这个的意思是在当前目录生成 *.pb.go 文件，而忽略 proto 文件中的 go_package 路径。\n统一 Makefile 与 scripts 中镜像相关的变量 对 make manifests 自动生成部署清单：\n文件：Dockerfile 目录：deploy/* 移除 Makefile 中以下变量\n转移至 scripts/env 中做设定，因不直接在 Makefile 文件中使用，简化结构。\n# 构建Docker容器变量 BUILD_GOOS ?= $(shell ${GO} env GOOS) IMAGE_FROM ?= scratch IMAGE_HOST ?= hub.docker.com IMAGE_NAME ?= ${IMAGE_HOST}/${NAMESPACE}/${SHORTNAME} IMAGE_VERSION ?= ${RELEASE_VERSION} # 部署与运行相关变量 BUILD_ENV ?= local DEPLOY_ENV ?= dev 更改 NAMESPACE 为部署使用的空间\n区别于 PRODUCT_CODE 表示产品代码或项目代码，而 NAMESPACE 表示租户空间，部署含义。\n改进 scripts/manifests.sh 后的变量\n移除 Makefile 中的 NAMESPACE 变量； BIZ_GROUP_APPID=hello DEPLOY_ENV=dev DEPLOY_ENV=local 部署的环境变量，值：dev test prod stress demo staging\n生成模版时支持自定义路径\nmake manifests TEMPLATES=kubernetes TEMPLATE_PATH=../gitops/deploy/kubernetes/dev/ 添加以下内容：\nscripts/kaniko.sh 移除 scripts/env 镜像变量 支持设置全局变量以 env-$DEPLOY_ENV-$BUILD_ENV 文件为准； Fixed go embed 存在 .svn 异常 问题\n+ make lint \u003e\u003e precheck environment \u003e\u003e generation release version \u003e\u003e generation code from proto files public/doc/embed.go:9:12: pattern openapi-spec/*: cannot embed directory openapi-spec/.svn: invalid name .svn public/doc/embed.go:9:12: pattern openapi-spec/*: cannot embed directory openapi-spec/.svn: invalid name .svn make: *** [Makefile:74: lint] Error 1 解决\n需更改为更明确的文件路径，避免使用 “*”\n// Code generated by \"grpc-kit-cli/0.3.1-beta.1\". DO NOT EDIT. package doc import ( \"embed\" ) //go:embed openapi-spec/*.js //go:embed openapi-spec/*.json //go:embed openapi-spec/*.html var Assets embed.FS [0.3.1] - 2023-04-09 Added 使用文档更新\n去除 gogo 模块文档； 更新 grpc 地址由 https://github.com/golang/protobuf 转变为 https://github.com/protocolbuffers/protobuf-go； 多平台镜像构建\n由于阿里云镜像中心不支持存放多架构容器更改为使用腾讯容器镜像服务； 当前多架构容器仅支持使用 “docker buildx”，暂不支持 “podman”； 添加依赖工具的下载\nmake protoc make protoc-gen-go make protoc-gen-go-grpc make protoc-gen-grpc-gateway make protoc-gen-openapiv2 仅版本号发生变更时才执行 sed\n更改了 scripts/version.sh 中的 update 方法； 仅当先前与当前版本号不一致才更改 microservice.openapiv2.yaml 文件； 更改了 /tmp/microservice.openapiv2.yaml 生成临时文件地址； Fixed 在 “oidc authenticator” 的 logger 存在空指针错误\n异常代码位置\ngithub.com/grpc-kit/pkg@v0.3.0/cfg/security.go:76 当设置的 “oidc issuer” 可访问，但未正常返回 “/.well-known/openid-configuration” 日志输出触发了空指针。\n[0.3.0] - 2023-03-10 Added 新增 “组织代码” 作为所有 proto 包名前缀\n默认 “组织代码” 取值为 “grpc-kit”\n根据规则自动生成内置变量：应用名称、服务包名、服务标题、服务代码\nAPPNAME、PROTO_PACKAGE、SERVICE_TITLE、SERVICE_CODE 对 microservice.proto 文件中的功能注解分离并声明式\n分离 “google.api.http” 功能到文件 “microservice.gateway.yaml”\n文档地址：https://github.com/googleapis/googleapis/blob/master/google/api/service.proto\n分离 “grpc.gateway.protoc_gen_openapiv2.options” 功能到文件 “microservice.openapiv2.yaml”\n文档地址：https://github.com/grpc-ecosystem/grpc-gateway/internal/descriptor/openapiconfig/openapiconfig.proto\n去掉 gogo 模块，升级 grpc-gateway v2 版本\n移除了 https://github.com/gogo/protobuf 的依赖； 升级了 grpc-gateway 为 v2 版本； 重新规范公知类 proto 的文件存放目录\n更改了 https://github.com/grpc-kit/api 原先 proto 路径规范； proto/v1/example.proto proto/v1/tracing.proto 更改为以下格式：\nknown/status/v1/response.proto known/example/v1/example.proto known/config/v1/config.proto 更改了 proto 的包名称： grpc.kit.api.proto.v1 更改为以下前缀：\ngrpc_kit.api.known. 更改库 “errors” 为 “errs” 防止对标准库重名\n更改 “github.com/grpc-kit/pkg/errors” 为 “github.com/grpc-kit/pkg/errs”； 升级 proto 使用 “google.golang.org/protobuf/proto” 版本 状态使用公知版本 “grpc_kit.api.known.status.Status” 结构体 移除 pkg/api 中使用 gogo 类库\n去除由 “protoc-gen-gogo” 生成的 “pb.go” 文件 统一使用新规范后的 “grpc-kit/api proto” 生成的 “pb.go” 文件 使用 gitlab-ci runner 为 shell 添加默认变量\n默认模版添加以下变量； # 默认全局变量 variables: CGO_ENABLED: \"0\" GIT_SSL_NO_VERIFY: \"true\" #GO111MODULE: \"on\" #GOPROXY: \"https://goproxy.cn\" #GOSUMDB: \"sum.golang.google.cn\" #GOPRIVATE: \"\" #GOPATH: \"/home/gitlab-runner/go\" Fixed make lint 首次无法正常运行\n首次代码初始化后 “api/” 目录下不存在 “*.pb.go” 代码，导致无法引用； 通过在执行 make lint 之前，做 “proto” 文件的序列化； ","categories":"","description":"","excerpt":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前 …","ref":"/docs/changelog/changelog-0.3/","tags":"","title":"CHANGELOG 0.3"},{"body":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前为Deprecated状态，此版本被移除 Fixed 功能的修复 Security 有关安全问题的修复 [Unreleased] [0.2.3] - 2022-11-28 Added grpc-kit/pkg 模块\n支持针对用户组进行鉴权 http_users 新增 “groups” 属性； 如果配置了 “security.authorization.allowed_groups” 则所有需要认证鉴权的接口必须属于该组里面，否则会403； 用户组区分大小写 添加最小化配置示例 未配置的模块，将不开启该功能 添加 “app-mini.yaml” 示例 添加健康检测服务可对外部网络 添加 “HTTP GET /ping” 接口，不过 grpc 服务 区别于 “HTTP GET /healthz”，该接口过 grpc 服务 grpc-kit/cli 模块\n支持自定义应用短名称 通过自定义\"SHORTNAME\"变量； 所有脚本应用shell更改 ubuntu默认为dash，明确使用\"/bin/bash\"，而非\"/bin/sh\"，会导致部分shell不支持 更改默认 http 服务端口 10080 至 8080 由于chrome等浏览器默认对\"10080\"端口存在\"ERR_UNSAFE_PORT\"告警，所以更改http默认为\"8080\" cli、pkg 组件版本号统一 为了解决统一编写变更记录(CHANGELOG.md) 支持自动生成 kubernetes 编排模版 新增 “DEPLOY_ENV” 变量，表示部署环境，如：dev、test、prod 新增 “BUILD_ENV” 变量，表示构建环境，一般用户自定义，默认为：local 新增指令 make manifests 生成基于 Kubernetes 的编排清单 模版路径：scripts/templates/kubernetes [0.2.2] - 2022-06-30 Changed 版本号格式的变更 旧规则以\"v\"为前缀，更新后不在带\"v\"为前缀，如：“v0.1.0-beta.3”，变更为：“0.1.0-beta.3”\nAdded 新增\"VERSION\"文件 用于描述当前分支版本，同时提供给CICD使用，如果当前分支未打成\"tag\"，则均说明是先行版本号，同时版本去掉以\"v\"开头；\n新增\"Makefile\"的帮助说明 make help [0.2.1] - 2022-06-09 Added “api/doc\"目录内容更改至\"public/doc” “api/proto\"目录更改为\"api/{product-code}/{short-name}” “cli\"新增\"repository\"参数用于说明代码仓库名 rpc客户端、服务端实例初始化转移至\"cfg\"实现 favicon.ico文件移至自定义http handler中实现 http接口统一以”/api/“为前缀对外暴露 ","categories":"","description":"","excerpt":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前 …","ref":"/docs/changelog/changelog-0.2/","tags":"","title":"CHANGELOG 0.2"},{"body":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前为Deprecated状态，此版本被移除 Fixed 功能的修复 Security 有关安全问题的修复 [Unreleased] [0.1.1] - 2021-11-10 Added 添加pkg/errors的示例 默认配置使用yaml格式 更新依赖的grpc-gateway等几个版本 根据product_code与short_name自动生成服务名称 服务结构添加rpc.Client属性，用于调用其他依赖服务 [0.1.0] - 2020-04-12 Added 首次发布 ","categories":"","description":"","excerpt":"Changelog 名称 说明 Added 添加新功能 Changed 功能的变更 Deprecated 未来会删除 Removed 之前 …","ref":"/docs/changelog/changelog-0.1/","tags":"","title":"CHANGELOG 0.1"},{"body":"简要概述 通过 systemd 来管理服务的生命周期。\n生成配置 在微服务代码目录，执行：\nmake manifests 将会生成 systemd 配置在 deploy/systemd/${APPNAME}.service 目录，把配置拷贝到目标主机 /usr/lib/systemd/system/${APPNAME}.service，启用服务：\nsystemctl enable ${APPNAME} systemctl start ${APPNAME} 服务模版 [Unit] After=network-online.target Documentation=http://(app.yaml:services.http_address)/openapi-spec/ Description=The ${SERVICE_CODE} microservice. For more API detailed, please refer to the docs [Service] Type=simple User=nobody Restart=always RestartSec=15s TimeoutSec=60s LimitNOFILE=65535 KillMode=control-group MemoryLimit=2048M ExecStart=/usr/local/${PRODUCT_CODE}/${SHORT_NAME}/${API_VERSION}/service --config /usr/local/${PRODUCT_CODE}/${SHORT_NAME}/${API_VERSION}/config/app.yaml [Install] Alias=${APPNAME}.service WantedBy=multi-user.target 其中变量 “SERVICE_CODE”、“PRODUCT_CODE”、“SHORT_NAME”、“APPNAME” 依据关键术语填写。\n","categories":"","description":"","excerpt":"简要概述 通过 systemd 来管理服务的生命周期。\n生成配置 在微服务代码目录，执行：\nmake manifests …","ref":"/docs/devops/deployment/systemd/","tags":"","title":"Systemd"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/spec-dev/flows/","tags":"","title":"分支流程"},{"body":"cfg 配置说明 当Debugger为\"debug\"模式或者开启opentracing的log_field http_body，且content-type为json时，开启记录用户请求体\n仅 LocalConfig 对外提供函数调用，其他均为方法内私有\n","categories":"","description":"","excerpt":"cfg 配置说明 当Debugger为\"debug\"模式或者开启opentracing的log_field http_body， …","ref":"/docs/spec-cfg/cfg/","tags":"","title":""},{"body":" 快速生成 grpc-kit 微单体应用模版，以符合相同规范、统一治理的服务脚手架，助力产品快速更新迭代。\ngRPC Kit 文档中心 源码跟踪 ","categories":"","description":"","excerpt":" 快速生成 grpc-kit 微单体应用模版，以符合相同规范、统一治理的服务脚手架，助力产品快速更新迭代。\ngRPC Kit 文档中心 源码 …","ref":"/","tags":"","title":"gRPC Kit"},{"body":" gGRPC Kit 是什么？\n一个以 Go 语言为主的微服务脚手架，主要基于以下几个核心类库实现：\ngrpc grpc-gateway ","categories":"","description":"","excerpt":" gGRPC Kit 是什么？\n一个以 Go 语言为主的微服务脚手架，主要基于以下几个核心类库实现：\ngrpc grpc-gateway ","ref":"/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"}]